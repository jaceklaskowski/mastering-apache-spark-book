<!doctype html><html lang=en class=no-js> <head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="Demystifying inner-workings of Apache Spark"><link href=https://books.japila.pl/apache-spark-internals/spark-SparkContext-creating-instance-internals/ rel=canonical><meta name=author content="Jacek Laskowski"><link rel="shortcut icon" href=../assets/images/favicon.png><meta name=generator content="mkdocs-1.1.2, mkdocs-material-6.0.2"><title>Creating SparkContext - The Internals of Apache Spark</title><link rel=stylesheet href=../assets/stylesheets/main.38780c08.min.css><link rel=stylesheet href=../assets/stylesheets/palette.3f72e892.min.css><link href=https://fonts.gstatic.com rel=preconnect crossorigin><link rel=stylesheet href="https://fonts.googleapis.com/css?family=Roboto:300,400,400i,700%7CRoboto+Mono&display=fallback"><style>body,input{font-family:"Roboto",-apple-system,BlinkMacSystemFont,Helvetica,Arial,sans-serif}code,kbd,pre{font-family:"Roboto Mono",SFMono-Regular,Consolas,Menlo,monospace}</style><script>window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)},ga.l=+new Date,ga("create","UA-151208281-5","auto"),ga("set","anonymizeIp",!0),ga("send","pageview"),document.addEventListener("DOMContentLoaded",function(){document.forms.search&&document.forms.search.query.addEventListener("blur",function(){if(this.value){var e=document.location.pathname;ga("send","pageview",e+"?q="+this.value)}})}),document.addEventListener("DOMContentSwitch",function(){ga("send","pageview",document.location.pathname)})</script><script async src=https://www.google-analytics.com/analytics.js></script></head> <body dir=ltr data-md-color-scheme data-md-color-primary=none data-md-color-accent=none> <input class=md-toggle data-md-toggle=drawer type=checkbox id=__drawer autocomplete=off> <input class=md-toggle data-md-toggle=search type=checkbox id=__search autocomplete=off> <label class=md-overlay for=__drawer></label> <div data-md-component=skip> <a href=#source-scala class=md-skip> Skip to content </a> </div> <div data-md-component=announce> </div> <header class=md-header data-md-component=header> <nav class="md-header-nav md-grid" aria-label=Header> <a href=https://books.japila.pl/apache-spark-internals title="The Internals of Apache Spark" class="md-header-nav__button md-logo" aria-label="The Internals of Apache Spark"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M19 2l-5 4.5v11l5-4.5V2M6.5 5C4.55 5 2.45 5.4 1 6.5v14.66c0 .25.25.5.5.5.1 0 .15-.07.25-.07 1.35-.65 3.3-1.09 4.75-1.09 1.95 0 4.05.4 5.5 1.5 1.35-.85 3.8-1.5 5.5-1.5 1.65 0 3.35.31 4.75 1.06.1.05.15.03.25.03.25 0 .5-.25.5-.5V6.5c-.6-.45-1.25-.75-2-1V19c-1.1-.35-2.3-.5-3.5-.5-1.7 0-4.15.65-5.5 1.5V6.5C10.55 5.4 8.45 5 6.5 5z"/></svg> </a> <label class="md-header-nav__button md-icon" for=__drawer> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2z"/></svg> </label> <div class=md-header-nav__title data-md-component=header-title> <div class=md-header-nav__ellipsis> <span class="md-header-nav__topic md-ellipsis"> The Internals of Apache Spark </span> <span class="md-header-nav__topic md-ellipsis"> Creating SparkContext </span> </div> </div> <label class="md-header-nav__button md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0116 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 019.5 16 6.5 6.5 0 013 9.5 6.5 6.5 0 019.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5z"/></svg> </label> <div class=md-search data-md-component=search role=dialog> <label class=md-search__overlay for=__search></label> <div class=md-search__inner role=search> <form class=md-search__form name=search> <input type=text class=md-search__input name=query aria-label=Search placeholder=Search autocapitalize=off autocorrect=off autocomplete=off spellcheck=false data-md-component=search-query data-md-state=active> <label class="md-search__icon md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0116 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 019.5 16 6.5 6.5 0 013 9.5 6.5 6.5 0 019.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5z"/></svg> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg> </label> <button type=reset class="md-search__icon md-icon" aria-label=Clear data-md-component=search-reset tabindex=-1> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M19 6.41L17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41z"/></svg> </button> </form> <div class=md-search__output> <div class=md-search__scrollwrap data-md-scrollfix> <div class=md-search-result data-md-component=search-result> <div class=md-search-result__meta> Initializing search </div> <ol class=md-search-result__list></ol> </div> </div> </div> </div> </div> <div class=md-header-nav__source> <a href=https://github.com/japila-books/apache-spark-internals/ title="Go to repository" class=md-source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 496 512"><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg> </div> <div class=md-source__repository> apache-spark-internals </div> </a> </div> </nav> </header> <div class=md-container data-md-component=container> <nav class="md-tabs md-tabs--active" aria-label=Tabs data-md-component=tabs> <div class="md-tabs__inner md-grid"> <ul class=md-tabs__list> <li class=md-tabs__item> <a href=.. class="md-tabs__link md-tabs__link--active"> Home </a> </li> <li class=md-tabs__item> <a href=../tools/spark-shell/ class=md-tabs__link> Tools </a> </li> <li class=md-tabs__item> <a href=../rdd/ class=md-tabs__link> RDD </a> </li> <li class=md-tabs__item> <a href=../metrics/ class=md-tabs__link> Metrics </a> </li> <li class=md-tabs__item> <a href=../demo/diskblockmanager-and-block-data/ class=md-tabs__link> Demos </a> </li> </ul> </div> </nav> <main class=md-main data-md-component=main> <div class="md-main__inner md-grid"> <div class="md-sidebar md-sidebar--primary" data-md-component=navigation> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--primary" aria-label=Navigation data-md-level=0> <label class=md-nav__title for=__drawer> <a href=https://books.japila.pl/apache-spark-internals title="The Internals of Apache Spark" class="md-nav__button md-logo" aria-label="The Internals of Apache Spark"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M19 2l-5 4.5v11l5-4.5V2M6.5 5C4.55 5 2.45 5.4 1 6.5v14.66c0 .25.25.5.5.5.1 0 .15-.07.25-.07 1.35-.65 3.3-1.09 4.75-1.09 1.95 0 4.05.4 5.5 1.5 1.35-.85 3.8-1.5 5.5-1.5 1.65 0 3.35.31 4.75 1.06.1.05.15.03.25.03.25 0 .5-.25.5-.5V6.5c-.6-.45-1.25-.75-2-1V19c-1.1-.35-2.3-.5-3.5-.5-1.7 0-4.15.65-5.5 1.5V6.5C10.55 5.4 8.45 5 6.5 5z"/></svg> </a> The Internals of Apache Spark </label> <div class=md-nav__source> <a href=https://github.com/japila-books/apache-spark-internals/ title="Go to repository" class=md-source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 496 512"><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg> </div> <div class=md-source__repository> apache-spark-internals </div> </a> </div> <ul class=md-nav__list data-md-scrollfix> <li class="md-nav__item md-nav__item--active md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-1 type=checkbox id=nav-1 checked> <label class=md-nav__link for=nav-1> Home <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label=Home data-md-level=1> <label class=md-nav__title for=nav-1> <span class="md-nav__icon md-icon"></span> Home </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=.. class=md-nav__link> Welcome </a> </li> <li class=md-nav__item> <a href=../overview/ class=md-nav__link> Overview </a> </li> <li class=md-nav__item> <a href=../SparkEnv/ class=md-nav__link> SparkEnv </a> </li> <li class=md-nav__item> <a href=../SparkConf/ class=md-nav__link> SparkConf </a> </li> <li class="md-nav__item md-nav__item--active md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-1-5 type=checkbox id=nav-1-5 checked> <label class=md-nav__link for=nav-1-5> SparkContext <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label=SparkContext data-md-level=2> <label class=md-nav__title for=nav-1-5> <span class="md-nav__icon md-icon"></span> SparkContext </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../SparkContext/ class=md-nav__link> SparkContext </a> </li> <li class="md-nav__item md-nav__item--active"> <input class="md-nav__toggle md-toggle" data-md-toggle=toc type=checkbox id=__toc> <a href=./ class="md-nav__link md-nav__link--active"> Creating SparkContext </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../spark-logging/ class=md-nav__link> Logging </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-1-7 type=checkbox id=nav-1-7> <label class=md-nav__link for=nav-1-7> Scheduler <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label=Scheduler data-md-level=2> <label class=md-nav__title for=nav-1-7> <span class="md-nav__icon md-icon"></span> Scheduler </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../scheduler/DAGScheduler/ class=md-nav__link> DAGScheduler </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-1-8 type=checkbox id=nav-1-8> <label class=md-nav__link for=nav-1-8> Storage <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label=Storage data-md-level=2> <label class=md-nav__title for=nav-1-8> <span class="md-nav__icon md-icon"></span> Storage </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../storage/BlockManager/ class=md-nav__link> BlockManager </a> </li> <li class=md-nav__item> <a href=../storage/BlockManagerId/ class=md-nav__link> BlockManagerId </a> </li> <li class=md-nav__item> <a href=../storage/BlockManagerInfo/ class=md-nav__link> BlockManagerInfo </a> </li> <li class=md-nav__item> <a href=../storage/BlockManagerMaster/ class=md-nav__link> BlockManagerMaster </a> </li> <li class=md-nav__item> <a href=../storage/BlockManagerMasterEndpoint/ class=md-nav__link> BlockManagerMasterEndpoint </a> </li> <li class=md-nav__item> <a href=../storage/BlockManagerSlaveEndpoint/ class=md-nav__link> BlockManagerSlaveEndpoint </a> </li> <li class=md-nav__item> <a href=../storage/BlockId/ class=md-nav__link> BlockId </a> </li> <li class=md-nav__item> <a href=../storage/BlockDataManager/ class=md-nav__link> BlockDataManager </a> </li> <li class=md-nav__item> <a href=../storage/DiskStore/ class=md-nav__link> DiskStore </a> </li> <li class=md-nav__item> <a href=../storage/DiskBlockManager/ class=md-nav__link> DiskBlockManager </a> </li> <li class=md-nav__item> <a href=../storage/MemoryStore/ class=md-nav__link> MemoryStore </a> </li> <li class=md-nav__item> <a href=../storage/BlockEvictionHandler/ class=md-nav__link> BlockEvictionHandler </a> </li> <li class=md-nav__item> <a href=../storage/BlockData/ class=md-nav__link> BlockData </a> </li> <li class=md-nav__item> <a href=../storage/BlockInfoManager/ class=md-nav__link> BlockInfoManager </a> </li> <li class=md-nav__item> <a href=../storage/BlockInfo/ class=md-nav__link> BlockInfo </a> </li> <li class=md-nav__item> <a href=../storage/DiskBlockObjectWriter/ class=md-nav__link> DiskBlockObjectWriter </a> </li> <li class=md-nav__item> <a href=../storage/BlockManagerSource/ class=md-nav__link> BlockManagerSource </a> </li> <li class=md-nav__item> <a href=../storage/ShuffleMetricsSource/ class=md-nav__link> ShuffleMetricsSource </a> </li> <li class=md-nav__item> <a href=../storage/ShuffleClient/ class=md-nav__link> ShuffleClient </a> </li> <li class=md-nav__item> <a href=../storage/BlockTransferService/ class=md-nav__link> BlockTransferService </a> </li> <li class=md-nav__item> <a href=../storage/NettyBlockTransferService/ class=md-nav__link> NettyBlockTransferService </a> </li> <li class=md-nav__item> <a href=../storage/NettyBlockRpcServer/ class=md-nav__link> NettyBlockRpcServer </a> </li> <li class=md-nav__item> <a href=../storage/ExternalShuffleClient/ class=md-nav__link> ExternalShuffleClient </a> </li> <li class=md-nav__item> <a href=../storage/OneForOneBlockFetcher/ class=md-nav__link> OneForOneBlockFetcher </a> </li> <li class=md-nav__item> <a href=../storage/ShuffleBlockFetcherIterator/ class=md-nav__link> ShuffleBlockFetcherIterator </a> </li> <li class=md-nav__item> <a href=../storage/RDDInfo/ class=md-nav__link> RDDInfo </a> </li> <li class=md-nav__item> <a href=../storage/StorageLevel/ class=md-nav__link> StorageLevel </a> </li> <li class=md-nav__item> <a href=../storage/StorageStatus/ class=md-nav__link> StorageStatus </a> </li> </ul> </nav> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-2 type=checkbox id=nav-2> <label class=md-nav__link for=nav-2> Tools <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label=Tools data-md-level=1> <label class=md-nav__title for=nav-2> <span class="md-nav__icon md-icon"></span> Tools </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../tools/spark-shell/ class=md-nav__link> spark-shell </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-3 type=checkbox id=nav-3> <label class=md-nav__link for=nav-3> RDD <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label=RDD data-md-level=1> <label class=md-nav__title for=nav-3> <span class="md-nav__icon md-icon"></span> RDD </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../rdd/ class=md-nav__link> Resilient Distributed Dataset </a> </li> <li class=md-nav__item> <a href=../rdd/RDD/ class=md-nav__link> RDD </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-3-3 type=checkbox id=nav-3-3> <label class=md-nav__link for=nav-3-3> RDDs <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label=RDDs data-md-level=2> <label class=md-nav__title for=nav-3-3> <span class="md-nav__icon md-icon"></span> RDDs </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../rdd/spark-rdd-CoGroupedRDD/ class=md-nav__link> CoGroupedRDD </a> </li> <li class=md-nav__item> <a href=../rdd/spark-rdd-HadoopRDD/ class=md-nav__link> HadoopRDD </a> </li> <li class=md-nav__item> <a href=../rdd/spark-rdd-MapPartitionsRDD/ class=md-nav__link> MapPartitionsRDD </a> </li> <li class=md-nav__item> <a href=../rdd/spark-rdd-NewHadoopRDD/ class=md-nav__link> NewHadoopRDD </a> </li> <li class=md-nav__item> <a href=../rdd/spark-rdd-OrderedRDDFunctions/ class=md-nav__link> OrderedRDDFunctions </a> </li> <li class=md-nav__item> <a href=../rdd/spark-rdd-ParallelCollectionRDD/ class=md-nav__link> ParallelCollectionRDD </a> </li> <li class=md-nav__item> <a href=../rdd/CheckpointRDD/ class=md-nav__link> CheckpointRDD </a> </li> <li class=md-nav__item> <a href=../rdd/ReliableCheckpointRDD/ class=md-nav__link> ReliableCheckpointRDD </a> </li> <li class=md-nav__item> <a href=../rdd/ShuffledRDD/ class=md-nav__link> ShuffledRDD </a> </li> <li class=md-nav__item> <a href=../rdd/spark-rdd-SubtractedRDD/ class=md-nav__link> SubtractedRDD </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-3-4 type=checkbox id=nav-3-4> <label class=md-nav__link for=nav-3-4> Operators <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label=Operators data-md-level=2> <label class=md-nav__title for=nav-3-4> <span class="md-nav__icon md-icon"></span> Operators </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../rdd/spark-rdd-operations/ class=md-nav__link> Operators </a> </li> <li class=md-nav__item> <a href=../rdd/spark-rdd-transformations/ class=md-nav__link> Transformations </a> </li> <li class=md-nav__item> <a href=../rdd/PairRDDFunctions/ class=md-nav__link> PairRDDFunctions </a> </li> <li class=md-nav__item> <a href=../rdd/spark-rdd-actions/ class=md-nav__link> Actions </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../rdd/Partitioner/ class=md-nav__link> Partitioner </a> </li> <li class=md-nav__item> <a href=../rdd/spark-rdd-lineage/ class=md-nav__link> RDD Lineage </a> </li> <li class=md-nav__item> <a href=../rdd/spark-rdd-caching/ class=md-nav__link> Caching and Persistence </a> </li> <li class=md-nav__item> <a href=../rdd/spark-rdd-partitions/ class=md-nav__link> Partitions and Partitioning </a> </li> <li class=md-nav__item> <a href=../rdd/spark-rdd-Partition/ class=md-nav__link> Partition </a> </li> <li class=md-nav__item> <a href=../rdd/RDDCheckpointData/ class=md-nav__link> RDDCheckpointData </a> </li> <li class=md-nav__item> <a href=../rdd/LocalRDDCheckpointData/ class=md-nav__link> LocalRDDCheckpointData </a> </li> <li class=md-nav__item> <a href=../rdd/ReliableRDDCheckpointData/ class=md-nav__link> ReliableRDDCheckpointData </a> </li> <li class=md-nav__item> <a href=../rdd/spark-rdd-shuffle/ class=md-nav__link> Shuffling </a> </li> <li class=md-nav__item> <a href=../rdd/spark-rdd-Dependency/ class=md-nav__link> Dependencies </a> </li> <li class=md-nav__item> <a href=../rdd/spark-rdd-NarrowDependency/ class=md-nav__link> NarrowDependency </a> </li> <li class=md-nav__item> <a href=../rdd/ShuffleDependency/ class=md-nav__link> ShuffleDependency </a> </li> <li class=md-nav__item> <a href=../rdd/Aggregator/ class=md-nav__link> Aggregator </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-3-18 type=checkbox id=nav-3-18> <label class=md-nav__link for=nav-3-18> Partitioners <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label=Partitioners data-md-level=2> <label class=md-nav__title for=nav-3-18> <span class="md-nav__icon md-icon"></span> Partitioners </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../rdd/HashPartitioner/ class=md-nav__link> HashPartitioner </a> </li> <li class=md-nav__item> <a href=../rdd/RangePartitioner/ class=md-nav__link> RangePartitioner </a> </li> </ul> </nav> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-4 type=checkbox id=nav-4> <label class=md-nav__link for=nav-4> Metrics <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label=Metrics data-md-level=1> <label class=md-nav__title for=nav-4> <span class="md-nav__icon md-icon"></span> Metrics </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../metrics/ class=md-nav__link> Spark Metrics </a> </li> <li class=md-nav__item> <a href=../metrics/configuration-properties/ class=md-nav__link> Configuration Properties </a> </li> <li class=md-nav__item> <a href=../metrics/MetricsSystem/ class=md-nav__link> MetricsSystem </a> </li> <li class=md-nav__item> <a href=../metrics/MetricsConfig/ class=md-nav__link> MetricsConfig </a> </li> <li class=md-nav__item> <a href=../metrics/Source/ class=md-nav__link> Source </a> </li> <li class=md-nav__item> <a href=../metrics/Sink/ class=md-nav__link> Sink </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-4-7 type=checkbox id=nav-4-7> <label class=md-nav__link for=nav-4-7> Sources <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label=Sources data-md-level=2> <label class=md-nav__title for=nav-4-7> <span class="md-nav__icon md-icon"></span> Sources </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../metrics/JvmSource/ class=md-nav__link> JvmSource </a> </li> <li class=md-nav__item> <a href=../metrics/DAGSchedulerSource/ class=md-nav__link> DAGSchedulerSource </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-4-8 type=checkbox id=nav-4-8> <label class=md-nav__link for=nav-4-8> Sinks <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label=Sinks data-md-level=2> <label class=md-nav__title for=nav-4-8> <span class="md-nav__icon md-icon"></span> Sinks </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../metrics/MetricsServlet/ class=md-nav__link> MetricsServlet </a> </li> </ul> </nav> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-5 type=checkbox id=nav-5> <label class=md-nav__link for=nav-5> Demos <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label=Demos data-md-level=1> <label class=md-nav__title for=nav-5> <span class="md-nav__icon md-icon"></span> Demos </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../demo/diskblockmanager-and-block-data/ class=md-nav__link> DiskBlockManager and Block Data </a> </li> </ul> </nav> </li> </ul> </nav> </div> </div> </div> <div class="md-sidebar md-sidebar--secondary" data-md-component=toc> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--secondary" aria-label="Table of contents"> </nav> </div> </div> </div> <div class=md-content> <article class="md-content__inner md-typeset"> <a href=https://github.com/japila-books/apache-spark-internals/edit/mkdocs-material/docs/spark-SparkContext-creating-instance-internals.md title="Edit this page" class="md-content__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20.71 7.04c.39-.39.39-1.04 0-1.41l-2.34-2.34c-.37-.39-1.02-.39-1.41 0l-1.84 1.83 3.75 3.75M3 17.25V21h3.75L17.81 9.93l-3.75-3.75L3 17.25z"/></svg> </a> <p>== Inside Creating SparkContext</p> <p>This document describes what happens when you xref:ROOT:SparkContext.adoc#creating-instance[create a new SparkContext].</p> <h2 id=source-scala>[source, scala]<a class=headerlink href=#source-scala title="Permanent link">&para;</a></h2> <p>import org.apache.spark.{SparkConf, SparkContext}</p> <p>// 1. Create Spark configuration val conf = new SparkConf() .setAppName("SparkMe Application") .setMaster("local[*]") // local mode</p> <p>// 2. Create Spark context val sc = new SparkContext(conf)</p> <hr> <p>NOTE: The example uses Spark in link:local/spark-local.adoc[local mode], but the initialization with link:spark-cluster.adoc[the other cluster modes] would follow similar steps.</p> <p>Creating <code>SparkContext</code> instance starts by setting the internal <code>allowMultipleContexts</code> field with the value of xref:ROOT:SparkContext.adoc#spark.driver.allowMultipleContexts[spark.driver.allowMultipleContexts] and marking this <code>SparkContext</code> instance as partially constructed. It makes sure that no other thread is creating a <code>SparkContext</code> instance in this JVM. It does so by synchronizing on <code>SPARK_CONTEXT_CONSTRUCTOR_LOCK</code> and using the internal atomic reference <code>activeContext</code> (that eventually has a fully-created <code>SparkContext</code> instance).</p> <h1 id=note>[NOTE]<a class=headerlink href=#note title="Permanent link">&para;</a></h1> <p>The entire code of <code>SparkContext</code> that creates a fully-working <code>SparkContext</code> instance is between two statements:</p> <h2 id=source-scala_1>[source, scala]<a class=headerlink href=#source-scala_1 title="Permanent link">&para;</a></h2> <p>SparkContext.markPartiallyConstructed(this, allowMultipleContexts)</p> <p>// the SparkContext code goes here</p> <h2 id=sparkcontextsetactivecontextthis-allowmultiplecontexts>SparkContext.setActiveContext(this, allowMultipleContexts)<a class=headerlink href=#sparkcontextsetactivecontextthis-allowmultiplecontexts title="Permanent link">&para;</a></h2> <p>====</p> <p>xref:ROOT:SparkContext.adoc#startTime[startTime] is set to the current time in milliseconds.</p> <p>&lt;<stopped, stopped>&gt; internal flag is set to <code>false</code>.</p> <p>The very first information printed out is the version of Spark as an INFO message:</p> <div class=highlight><pre><span></span><code>INFO SparkContext: Running Spark version 2.0.0-SNAPSHOT
</code></pre></div> <p>TIP: You can use xref:ROOT:SparkContext.adoc#version[version] method to learn about the current Spark version or <code>org.apache.spark.SPARK_VERSION</code> value.</p> <p>A xref:scheduler:LiveListenerBus.adoc#creating-instance[LiveListenerBus instance is created] (as <code>listenerBus</code>).</p> <p>[[sparkUser]] The xref:ROOT:SparkContext.adoc#sparkUser[current user name] is computed.</p> <p>CAUTION: FIXME Where is <code>sparkUser</code> used?</p> <p>It saves the input <code>SparkConf</code> (as <code>_conf</code>).</p> <p>CAUTION: FIXME Review <code>_conf.validateSettings()</code></p> <p>It ensures that the first mandatory setting - <code>spark.master</code> is defined. <code>SparkException</code> is thrown if not.</p> <div class=highlight><pre><span></span><code>A master URL must be set in your configuration
</code></pre></div> <p>It ensures that the other mandatory setting - <code>spark.app.name</code> is defined. <code>SparkException</code> is thrown if not.</p> <div class=highlight><pre><span></span><code>An application name must be set in your configuration
</code></pre></div> <p>For link:yarn/spark-yarn-cluster-yarnclusterschedulerbackend.adoc[Spark on YARN in cluster deploy mode], it checks existence of <code>spark.yarn.app.id</code>. <code>SparkException</code> is thrown if it does not exist.</p> <div class=highlight><pre><span></span><code>Detected yarn cluster mode, but isn&#39;t running on a cluster. Deployment to YARN is not supported directly by SparkContext. Please use spark-submit.
</code></pre></div> <p>CAUTION: FIXME How to "trigger" the exception? What are the steps?</p> <p>When <code>spark.logConf</code> is enabled xref:ROOT:SparkConf.adoc[SparkConf.toDebugString] is called.</p> <p>NOTE: <code>SparkConf.toDebugString</code> is called very early in the initialization process and other settings configured afterwards are not included. Use <code>sc.getConf.toDebugString</code> once SparkContext is initialized.</p> <p>The driver's host and port are set if missing. link:spark-driver.adoc#spark_driver_host[spark.driver.host] becomes the value of &lt;<localhostname, utils.localhostname>&gt; (or an exception is thrown) while link:spark-driver.adoc#spark_driver_port[spark.driver.port] is set to <code>0</code>.</p> <p>NOTE: link:spark-driver.adoc#spark_driver_host[spark.driver.host] and link:spark-driver.adoc#spark_driver_port[spark.driver.port] are expected to be set on the driver. It is later asserted by xref:core:SparkEnv.adoc#createDriverEnv[SparkEnv].</p> <p>xref:executor:Executor.adoc#spark.executor.id[spark.executor.id] setting is set to <code>driver</code>.</p> <p>TIP: Use <code>sc.getConf.get("spark.executor.id")</code> to know where the code is executed -- xref:core:SparkEnv.adoc[driver or executors].</p> <p>It sets the jars and files based on <code>spark.jars</code> and <code>spark.files</code>, respectively. These are files that are required for proper task execution on executors.</p> <p>If xref:spark-history-server:EventLoggingListener.adoc[event logging] is enabled, i.e. link:EventLoggingListener.adoc#spark_eventLog_enabled[spark.eventLog.enabled] flag is <code>true</code>, the internal field <code>_eventLogDir</code> is set to the value of link:EventLoggingListener.adoc#spark_eventLog_dir[spark.eventLog.dir] setting or the default value <code>/tmp/spark-events</code>.</p> <p>[[_eventLogCodec]] Also, if xref:spark-history-server:EventLoggingListener.adoc#spark_eventLog_compress[spark.eventLog.compress] is enabled (it is not by default), the short name of the xref<img alt=ðŸ‡®ðŸ‡´ class=emojione src=https://cdnjs.cloudflare.com/ajax/libs/emojione/2.2.7/assets/png/1f1ee-1f1f4.png title=:io:>CompressionCodec.adoc[CompressionCodec] is assigned to <code>_eventLogCodec</code>. The config key is xref:core:BroadcastManager.adoc#spark_io_compression_codec[spark.io.compression.codec] (default: <code>lz4</code>).</p> <p>TIP: Read about compression codecs in xref:core:BroadcastManager.adoc#compression[Compression].</p> <p>=== [[_listenerBus]] Creating LiveListenerBus</p> <p><code>SparkContext</code> creates a xref:scheduler:LiveListenerBus.adoc#creating-instance[LiveListenerBus].</p> <p>=== [[_statusStore]] Creating Live AppStatusStore</p> <p><code>SparkContext</code> requests <code>AppStatusStore</code> to create a xref:core:AppStatusStore.adoc#createLiveStore[live store] (i.e. the <code>AppStatusStore</code> for a live Spark application) and requests &lt;<listenerbus, livelistenerbus>&gt; to add the xref:core:AppStatusStore.adoc#listener[AppStatusListener] to the xref:scheduler:LiveListenerBus.adoc#addToStatusQueue[status queue].</p> <p>NOTE: The current <code>AppStatusStore</code> is available as xref:ROOT:SparkContext.adoc#statusStore[statusStore] property of the <code>SparkContext</code>.</p> <p>=== [[_env]] Creating SparkEnv</p> <p><code>SparkContext</code> creates a &lt;<createsparkenv, sparkenv>&gt; and requests <code>SparkEnv</code> to xref:core:SparkEnv.adoc#set[use the instance as the default SparkEnv].</p> <p>CAUTION: FIXME Describe the following steps.</p> <p><code>MetadataCleaner</code> is created.</p> <p>CAUTION: FIXME What's MetadataCleaner?</p> <p>=== [[_statusTracker]] Creating SparkStatusTracker</p> <p><code>SparkContext</code> creates a link:spark-sparkcontext-SparkStatusTracker.adoc#creating-instance[SparkStatusTracker] (with itself and the &lt;&lt;_statusStore, AppStatusStore&gt;&gt;).</p> <p>=== [[_progressBar]] Creating ConsoleProgressBar</p> <p><code>SparkContext</code> creates the optional link:spark-sparkcontext-ConsoleProgressBar.adoc#creating-instance[ConsoleProgressBar] when link:spark-webui-properties.adoc#spark.ui.showConsoleProgress[spark.ui.showConsoleProgress] property is enabled and the <code>INFO</code> logging level for <code>SparkContext</code> is disabled.</p> <p>=== [[_ui]][[ui]] Creating SparkUI</p> <p><code>SparkContext</code> creates a link:spark-webui-SparkUI.adoc#create[SparkUI] when link:spark-webui-properties.adoc#spark.ui.enabled[spark.ui.enabled] configuration property is enabled (i.e. <code>true</code>) with the following:</p> <ul> <li> <p>&lt;&lt;_statusStore, AppStatusStore&gt;&gt;</p> </li> <li> <p>Name of the Spark application that is exactly the value of xref:ROOT:SparkConf.adoc#spark.app.name[spark.app.name] configuration property</p> </li> <li> <p>Empty base path</p> </li> </ul> <p>NOTE: link:spark-webui-properties.adoc#spark.ui.enabled[spark.ui.enabled] Spark property is assumed enabled when undefined.</p> <p>CAUTION: FIXME Where's <code>_ui</code> used?</p> <p>A Hadoop configuration is created. See xref:ROOT:SparkContext.adoc#hadoopConfiguration[Hadoop Configuration].</p> <p>[[jars]] If there are jars given through the SparkContext constructor, they are added using <code>addJar</code>.</p> <p>[[files]] If there were files specified, they are added using xref:ROOT:SparkContext.adoc#addFile[addFile].</p> <p>At this point in time, the amount of memory to allocate to each executor (as <code>_executorMemory</code>) is calculated. It is the value of xref:executor:Executor.adoc#spark.executor.memory[spark.executor.memory] setting, or xref:ROOT:SparkContext.adoc#environment-variables[SPARK_EXECUTOR_MEMORY] environment variable (or currently-deprecated <code>SPARK_MEM</code>), or defaults to <code>1024</code>.</p> <p><code>_executorMemory</code> is later available as <code>sc.executorMemory</code> and used for LOCAL_CLUSTER_REGEX, link:spark-standalone.adoc#SparkDeploySchedulerBackend[Spark Standalone's SparkDeploySchedulerBackend], to set <code>executorEnvs("SPARK_EXECUTOR_MEMORY")</code>, MesosSchedulerBackend, CoarseMesosSchedulerBackend.</p> <p>The value of <code>SPARK_PREPEND_CLASSES</code> environment variable is included in <code>executorEnvs</code>.</p> <h1 id=caution>[CAUTION]<a class=headerlink href=#caution title="Permanent link">&para;</a></h1> <p>FIXME</p> <ul> <li>What's <code>_executorMemory</code>?</li> <li>What's the unit of the value of <code>_executorMemory</code> exactly?</li> <li>What are "SPARK_TESTING", "spark.testing"? How do they contribute to <code>executorEnvs</code>?</li> <li> <h1 id=whats-executorenvs>What's <code>executorEnvs</code>?<a class=headerlink href=#whats-executorenvs title="Permanent link">&para;</a></h1> </li> </ul> <p>The Mesos scheduler backend's configuration is included in <code>executorEnvs</code>, i.e. xref:ROOT:SparkContext.adoc#environment-variables[SPARK_EXECUTOR_MEMORY], <code>_conf.getExecutorEnv</code>, and <code>SPARK_USER</code>.</p> <p>[[_heartbeatReceiver]] <code>SparkContext</code> registers link:spark-HeartbeatReceiver.adoc[HeartbeatReceiver RPC endpoint].</p> <p><code>SparkContext</code> object is requested to xref:ROOT:SparkContext.adoc#createTaskScheduler[create the SchedulerBackend with the TaskScheduler] (for the given master URL) and the result becomes the internal <code>_schedulerBackend</code> and <code>_taskScheduler</code>.</p> <p>NOTE: The internal <code>_schedulerBackend</code> and <code>_taskScheduler</code> are used by <code>schedulerBackend</code> and <code>taskScheduler</code> methods, respectively.</p> <p>xref:scheduler:DAGScheduler.adoc#creating-instance[DAGScheduler is created] (as <code>_dagScheduler</code>).</p> <p>[[TaskSchedulerIsSet]] <code>SparkContext</code> sends a blocking link:spark-HeartbeatReceiver.adoc#TaskSchedulerIsSet[<code>TaskSchedulerIsSet</code> message to HeartbeatReceiver RPC endpoint] (to inform that the <code>TaskScheduler</code> is now available).</p> <p>=== [[taskScheduler-start]] Starting TaskScheduler</p> <p><code>SparkContext</code> xref:scheduler:TaskScheduler.adoc#start[starts <code>TaskScheduler</code>].</p> <p>=== [[_applicationId]][[_applicationAttemptId]] Setting Spark Application's and Execution Attempt's IDs -- <code>_applicationId</code> and <code>_applicationAttemptId</code></p> <p><code>SparkContext</code> sets the internal fields -- <code>_applicationId</code> and <code>_applicationAttemptId</code> -- (using <code>applicationId</code> and <code>applicationAttemptId</code> methods from the xref:scheduler:TaskScheduler.adoc#contract[TaskScheduler Contract]).</p> <p>NOTE: <code>SparkContext</code> requests <code>TaskScheduler</code> for the xref:scheduler:TaskScheduler.adoc#applicationId[unique identifier of a Spark application] (that is currently only implemented by xref:scheduler:TaskSchedulerImpl.adoc#applicationId[TaskSchedulerImpl] that uses <code>SchedulerBackend</code> to xref:scheduler:SchedulerBackend.adoc#applicationId[request the identifier]).</p> <p>NOTE: The unique identifier of a Spark application is used to initialize link:spark-webui-SparkUI.adoc#setAppId[SparkUI] and xref:storage:BlockManager.adoc#initialize[BlockManager].</p> <p>NOTE: <code>_applicationAttemptId</code> is used when <code>SparkContext</code> is requested for the xref:ROOT:SparkContext.adoc#applicationAttemptId[unique identifier of execution attempt of a Spark application] and when <code>EventLoggingListener</code> xref:spark-history-server:EventLoggingListener.adoc#creating-instance[is created].</p> <p>=== [[spark.app.id]] Setting spark.app.id Spark Property in SparkConf</p> <p><code>SparkContext</code> sets xref:ROOT:SparkConf.adoc#spark.app.id[spark.app.id] property to be the &lt;&lt;_applicationId, unique identifier of a Spark application&gt;&gt; and, if enabled, link:spark-webui-SparkUI.adoc#setAppId[passes it on to <code>SparkUI</code>].</p> <p>=== [[BlockManager-initialization]] Initializing BlockManager</p> <p>The xref:storage:BlockManager.adoc#initialize[BlockManager (for the driver) is initialized] (with <code>_applicationId</code>).</p> <p>=== [[MetricsSystem-start]] Starting MetricsSystem</p> <p><code>SparkContext</code> requests the <code>MetricsSystem</code> to link:spark-metrics-MetricsSystem.adoc#start[start].</p> <p>NOTE: <code>SparkContext</code> starts <code>MetricsSystem</code> after &lt;<spark.app.id, setting spark.app.id spark property>&gt; as <code>MetricsSystem</code> uses it to link:spark-metrics-MetricsSystem.adoc#buildRegistryName[build unique identifiers fo metrics sources].</p> <p>=== [[MetricsSystem-getServletHandlers]] Requesting JSON Servlet Handler</p> <p><code>SparkContext</code> requests the <code>MetricsSystem</code> for a link:spark-metrics-MetricsSystem.adoc#getServletHandlers[JSON servlet handler] and requests the &lt;&lt;_ui, SparkUI&gt;&gt; to link:spark-webui-WebUI.adoc#attachHandler[attach it].</p> <p>[[_eventLogger]] <code>_eventLogger</code> is created and started if <code>isEventLogEnabled</code>. It uses xref:spark-history-server:EventLoggingListener.adoc[EventLoggingListener] that gets registered to xref:scheduler:LiveListenerBus.adoc[].</p> <p>CAUTION: FIXME Why is <code>_eventLogger</code> required to be the internal field of SparkContext? Where is this used?</p> <p>[[ExecutorAllocationManager]] For xref:ROOT:spark-dynamic-allocation.adoc[], link:spark-ExecutorAllocationManager.adoc#creating-instance[<code>ExecutorAllocationManager</code> is created] (as <code>_executorAllocationManager</code>) and immediately link:spark-ExecutorAllocationManager.adoc#start[started].</p> <p>NOTE: <code>_executorAllocationManager</code> is exposed (as a method) to link:yarn/spark-yarn-yarnschedulerbackend.adoc#reset[YARN scheduler backends to reset their state to the initial state].</p> <p>[[_cleaner]][[ContextCleaner]] With xref:ROOT:configuration-properties.adoc#spark.cleaner.referenceTracking[spark.cleaner.referenceTracking] configuration property enabled, <code>SparkContext</code> xref:core:ContextCleaner.adoc#creating-instance[creates <code>ContextCleaner</code>] (as <code>_cleaner</code>) and xref:core:ContextCleaner.adoc#start[started] immediately. Otherwise, <code>_cleaner</code> is empty.</p> <p>CAUTION: FIXME It'd be quite useful to have all the properties with their default values in <code>sc.getConf.toDebugString</code>, so when a configuration is not included but does change Spark runtime configuration, it should be added to <code>_conf</code>.</p> <p>[[registering_SparkListeners]] It &lt;<setupandstartlistenerbus, registers user-defined listeners and starts &lt;code>SparkListenerEvent</code> event delivery to the listeners>&gt;.</p> <p>[[postEnvironmentUpdate]] <code>postEnvironmentUpdate</code> is called that posts xref:ROOT:SparkListener.adoc#SparkListenerEnvironmentUpdate[SparkListenerEnvironmentUpdate] message on xref:scheduler:LiveListenerBus.adoc[] with information about Task Scheduler's scheduling mode, added jar and file paths, and other environmental details. They are displayed in web UI's link:spark-webui-environment.adoc[Environment tab].</p> <p>[[postApplicationStart]] xref:ROOT:SparkListener.adoc#SparkListenerApplicationStart[SparkListenerApplicationStart] message is posted to xref:scheduler:LiveListenerBus.adoc[] (using the internal <code>postApplicationStart</code> method).</p> <p>[[postStartHook]] <code>TaskScheduler</code> xref:scheduler:TaskScheduler.adoc#postStartHook[is notified that <code>SparkContext</code> is almost fully initialized].</p> <p>NOTE: xref:scheduler:TaskScheduler.adoc#postStartHook[TaskScheduler.postStartHook] does nothing by default, but custom implementations offer more advanced features, i.e. <code>TaskSchedulerImpl</code> xref:scheduler:TaskSchedulerImpl.adoc#postStartHook[blocks the current thread until <code>SchedulerBackend</code> is ready]. There is also <code>YarnClusterScheduler</code> for Spark on YARN in <code>cluster</code> deploy mode.</p> <p>=== [[registerSource]] Registering Metrics Sources</p> <p><code>SparkContext</code> requests <code>MetricsSystem</code> to link:spark-metrics-MetricsSystem.adoc#registerSource[register metrics sources] for the following services:</p> <p>. xref:scheduler:DAGScheduler.adoc#metricsSource[DAGScheduler] . link:spark-BlockManager-BlockManagerSource.adoc[BlockManager] . link:spark-ExecutorAllocationManager.adoc#executorAllocationManagerSource[ExecutorAllocationManager] (for xref:ROOT:spark-dynamic-allocation.adoc[])</p> <p>=== [[addShutdownHook]] Adding Shutdown Hook</p> <p><code>SparkContext</code> adds a shutdown hook (using <code>ShutdownHookManager.addShutdownHook()</code>).</p> <p>You should see the following DEBUG message in the logs:</p> <div class=highlight><pre><span></span><code>DEBUG Adding shutdown hook
</code></pre></div> <p>CAUTION: FIXME ShutdownHookManager.addShutdownHook()</p> <p>Any non-fatal Exception leads to termination of the Spark context instance.</p> <p>CAUTION: FIXME What does <code>NonFatal</code> represent in Scala?</p> <p>CAUTION: FIXME Finish me</p> <p>=== [[nextShuffleId]][[nextRddId]] Initializing nextShuffleId and nextRddId Internal Counters</p> <p><code>nextShuffleId</code> and <code>nextRddId</code> start with <code>0</code>.</p> <p>CAUTION: FIXME Where are <code>nextShuffleId</code> and <code>nextRddId</code> used?</p> <p>A new instance of Spark context is created and ready for operation.</p> <p>=== [[getClusterManager]] Loading External Cluster Manager for URL (getClusterManager method)</p> <h2 id=source-scala_2>[source, scala]<a class=headerlink href=#source-scala_2 title="Permanent link">&para;</a></h2> <h2 id=getclustermanagerurl-string-optionexternalclustermanager>getClusterManager(url: String): Option[ExternalClusterManager]<a class=headerlink href=#getclustermanagerurl-string-optionexternalclustermanager title="Permanent link">&para;</a></h2> <p><code>getClusterManager</code> loads xref:scheduler:ExternalClusterManager.adoc[] that xref:scheduler:ExternalClusterManager.adoc#canCreate[can handle the input <code>url</code>].</p> <p>If there are two or more external cluster managers that could handle <code>url</code>, a <code>SparkException</code> is thrown:</p> <div class=highlight><pre><span></span><code>Multiple Cluster Managers ([serviceLoaders]) registered for the url [url].
</code></pre></div> <p>NOTE: <code>getClusterManager</code> uses Java's link:++<a href=https://docs.oracle.com/javase/8/docs/api/java/util/ServiceLoader.html#load-java.lang.Class-java.lang.ClassLoader-++[ServiceLoader.load>https://docs.oracle.com/javase/8/docs/api/java/util/ServiceLoader.html#load-java.lang.Class-java.lang.ClassLoader-++[ServiceLoader.load</a>] method.</p> <p>NOTE: <code>getClusterManager</code> is used to find a cluster manager for a master URL when xref:ROOT:SparkContext.adoc#createTaskScheduler[creating a <code>SchedulerBackend</code> and a <code>TaskScheduler</code> for the driver].</p> <p>=== [[setupAndStartListenerBus]] setupAndStartListenerBus</p> <h2 id=source-scala_3>[source, scala]<a class=headerlink href=#source-scala_3 title="Permanent link">&para;</a></h2> <h2 id=setupandstartlistenerbus-unit>setupAndStartListenerBus(): Unit<a class=headerlink href=#setupandstartlistenerbus-unit title="Permanent link">&para;</a></h2> <p><code>setupAndStartListenerBus</code> is an internal method that reads xref:ROOT:configuration-properties.adoc#spark.extraListeners[spark.extraListeners] configuration property from the current xref:ROOT:SparkConf.adoc[SparkConf] to create and register xref:ROOT:SparkListener.adoc#SparkListenerInterface[SparkListenerInterface] listeners.</p> <p>It expects that the class name represents a <code>SparkListenerInterface</code> listener with one of the following constructors (in this order):</p> <ul> <li>a single-argument constructor that accepts xref:ROOT:SparkConf.adoc[SparkConf]</li> <li>a zero-argument constructor</li> </ul> <p><code>setupAndStartListenerBus</code> xref:scheduler:LiveListenerBus.adoc#ListenerBus-addListener[registers every listener class].</p> <p>You should see the following INFO message in the logs:</p> <div class=highlight><pre><span></span><code>INFO Registered listener [className]
</code></pre></div> <p>It xref:scheduler:LiveListenerBus.adoc#start[starts LiveListenerBus] and records it in the internal <code>_listenerBusStarted</code>.</p> <p>When no single-<code>SparkConf</code> or zero-argument constructor could be found for a class name in xref:ROOT:configuration-properties.adoc#spark.extraListeners[spark.extraListeners] configuration property, a <code>SparkException</code> is thrown with the message:</p> <div class=highlight><pre><span></span><code>[className] did not have a zero-argument constructor or a single-argument constructor that accepts SparkConf. Note: if the class is defined inside of another Scala class, then its constructors may accept an implicit parameter that references the enclosing class; in this case, you must define the listener as a top-level class in order to prevent this extra parameter from breaking Spark&#39;s ability to find a valid constructor.
</code></pre></div> <p>Any exception while registering a xref:ROOT:SparkListener.adoc#SparkListenerInterface[SparkListenerInterface] listener xref:ROOT:SparkContext.adoc#stop[stops the SparkContext] and a <code>SparkException</code> is thrown and the source exception's message.</p> <div class=highlight><pre><span></span><code>Exception when registering SparkListener
</code></pre></div> <h1 id=tip>[TIP]<a class=headerlink href=#tip title="Permanent link">&para;</a></h1> <p>Set <code>INFO</code> on <code>org.apache.spark.SparkContext</code> logger to see the extra listeners being registered.</p> <h1 id=info-sparkcontext-registered-listener-pljapilasparkcustomsparklistener><div class=highlight><pre><span></span><code>INFO SparkContext: Registered listener pl.japila.spark.CustomSparkListener
</code></pre></div><a class=headerlink href=#info-sparkcontext-registered-listener-pljapilasparkcustomsparklistener title="Permanent link">&para;</a></h1> <p>=== [[createSparkEnv]] Creating SparkEnv for Driver -- <code>createSparkEnv</code> Method</p> <h2 id=source-scala_4>[source, scala]<a class=headerlink href=#source-scala_4 title="Permanent link">&para;</a></h2> <p>createSparkEnv( conf: SparkConf, isLocal: Boolean, listenerBus: LiveListenerBus): SparkEnv</p> <hr> <p><code>createSparkEnv</code> simply delegates the call to xref:core:SparkEnv.adoc#createDriverEnv[SparkEnv to create a <code>SparkEnv</code> for the driver].</p> <p>It calculates the number of cores to <code>1</code> for <code>local</code> master URL, the number of processors available for JVM for <code>*</code> or the exact number in the master URL, or <code>0</code> for the cluster master URLs.</p> <p>=== [[getCurrentUserName]] <code>Utils.getCurrentUserName</code> Method</p> <h2 id=source-scala_5>[source, scala]<a class=headerlink href=#source-scala_5 title="Permanent link">&para;</a></h2> <h2 id=getcurrentusername-string>getCurrentUserName(): String<a class=headerlink href=#getcurrentusername-string title="Permanent link">&para;</a></h2> <p><code>getCurrentUserName</code> computes the user name who has started the xref:ROOT:SparkContext.adoc[SparkContext] instance.</p> <p>NOTE: It is later available as xref:ROOT:SparkContext.adoc#sparkUser[SparkContext.sparkUser].</p> <p>Internally, it reads xref:ROOT:SparkContext.adoc#SPARK_USER[SPARK_USER] environment variable and, if not set, reverts to Hadoop Security API's <code>UserGroupInformation.getCurrentUser().getShortUserName()</code>.</p> <p>NOTE: It is another place where Spark relies on Hadoop API for its operation.</p> <p>=== [[localHostName]] <code>Utils.localHostName</code> Method</p> <p><code>localHostName</code> computes the local host name.</p> <p>It starts by checking <code>SPARK_LOCAL_HOSTNAME</code> environment variable for the value. If it is not defined, it uses <code>SPARK_LOCAL_IP</code> to find the name (using <code>InetAddress.getByName</code>). If it is not defined either, it calls <code>InetAddress.getLocalHost</code> for the name.</p> <p>NOTE: <code>Utils.localHostName</code> is executed while xref:ROOT:SparkContext.adoc#creating-instance[<code>SparkContext</code> is created] and also to compute the default value of link:spark-driver.adoc#spark_driver_host[spark.driver.host Spark property].</p> <p>CAUTION: FIXME Review the rest.</p> <p>=== [[stopped]] <code>stopped</code> Flag</p> <p>CAUTION: FIXME Where is this used?</p> <hr> <div class=md-source-date> <small> Last update: 2020-10-05 </small> </div> </article> </div> </div> </main> <footer class=md-footer> <div class=md-footer-nav> <nav class="md-footer-nav__inner md-grid" aria-label=Footer> <a href=../SparkContext/ class="md-footer-nav__link md-footer-nav__link--prev" rel=prev> <div class="md-footer-nav__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg> </div> <div class=md-footer-nav__title> <div class=md-ellipsis> <span class=md-footer-nav__direction> Previous </span> SparkContext </div> </div> </a> <a href=../spark-logging/ class="md-footer-nav__link md-footer-nav__link--next" rel=next> <div class=md-footer-nav__title> <div class=md-ellipsis> <span class=md-footer-nav__direction> Next </span> Logging </div> </div> <div class="md-footer-nav__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11H4z"/></svg> </div> </a> </nav> </div> <div class="md-footer-meta md-typeset"> <div class="md-footer-meta__inner md-grid"> <div class=md-footer-copyright> <div class=md-footer-copyright__highlight> Copyright &copy; 2020 <a href=https://twitter.com/jaceklaskowski target=_blank rel=noopener>Jacek Laskowski</a> </div> Made with <a href=https://squidfunk.github.io/mkdocs-material/ target=_blank rel=noopener> Material for MkDocs </a> </div> <div class=md-footer-social> <a href=https://github.com/jaceklaskowski target=_blank rel=noopener title=github.com class=md-footer-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 496 512"><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg> </a> <a href=https://twitter.com/jaceklaskowski target=_blank rel=noopener title=twitter.com class=md-footer-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 512 512"><path d="M459.37 151.716c.325 4.548.325 9.097.325 13.645 0 138.72-105.583 298.558-298.558 298.558-59.452 0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055 0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421 0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391 0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04 0-57.828 46.782-104.934 104.934-104.934 30.213 0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253z"/></svg> </a> <a href=https://linkedin.com/in/jaceklaskowski target=_blank rel=noopener title=linkedin.com class=md-footer-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><path d="M416 32H31.9C14.3 32 0 46.5 0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6 0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3zM135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3 0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2 0 38.5 17.3 38.5 38.5 0 21.3-17.2 38.5-38.5 38.5zm282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6 0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2 0 79.7 44.3 79.7 101.9V416z"/></svg> </a> </div> </div> </div> </footer> </div> <script src=../assets/javascripts/vendor.77e55a48.min.js></script> <script src=../assets/javascripts/bundle.9554a270.min.js></script><script id=__lang type=application/json>{"clipboard.copy": "Copy to clipboard", "clipboard.copied": "Copied to clipboard", "search.config.lang": "en", "search.config.pipeline": "trimmer, stopWordFilter", "search.config.separator": "[\\s\\-]+", "search.result.placeholder": "Type to start searching", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.term.missing": "Missing"}</script> <script>
        app = initialize({
          base: "..",
          features: ['navigation.tabs', 'navigation.instant'],
          search: Object.assign({
            worker: "../assets/javascripts/worker/search.4ac00218.min.js"
          }, typeof search !== "undefined" && search)
        })
      </script> </body> </html>