<!doctype html><html lang=en class=no-js> <head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="Demystifying inner-workings of Apache Spark"><link href=https://books.japila.pl/apache-spark-internals/scheduler/DAGScheduler/ rel=canonical><meta name=author content="Jacek Laskowski"><link rel="shortcut icon" href=../../assets/images/favicon.png><meta name=generator content="mkdocs-1.1.2, mkdocs-material-6.0.2"><title>DAGScheduler - The Internals of Apache Spark</title><link rel=stylesheet href=../../assets/stylesheets/main.38780c08.min.css><link rel=stylesheet href=../../assets/stylesheets/palette.3f72e892.min.css><link href=https://fonts.gstatic.com rel=preconnect crossorigin><link rel=stylesheet href="https://fonts.googleapis.com/css?family=Roboto:300,400,400i,700%7CRoboto+Mono&display=fallback"><style>body,input{font-family:"Roboto",-apple-system,BlinkMacSystemFont,Helvetica,Arial,sans-serif}code,kbd,pre{font-family:"Roboto Mono",SFMono-Regular,Consolas,Menlo,monospace}</style><script>window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)},ga.l=+new Date,ga("create","UA-151208281-5","auto"),ga("set","anonymizeIp",!0),ga("send","pageview"),document.addEventListener("DOMContentLoaded",function(){document.forms.search&&document.forms.search.query.addEventListener("blur",function(){if(this.value){var e=document.location.pathname;ga("send","pageview",e+"?q="+this.value)}})}),document.addEventListener("DOMContentSwitch",function(){ga("send","pageview",document.location.pathname)})</script><script async src=https://www.google-analytics.com/analytics.js></script></head> <body dir=ltr data-md-color-scheme data-md-color-primary=none data-md-color-accent=none> <input class=md-toggle data-md-toggle=drawer type=checkbox id=__drawer autocomplete=off> <input class=md-toggle data-md-toggle=search type=checkbox id=__search autocomplete=off> <label class=md-overlay for=__drawer></label> <div data-md-component=skip> <a href=#note class=md-skip> Skip to content </a> </div> <div data-md-component=announce> </div> <header class=md-header data-md-component=header> <nav class="md-header-nav md-grid" aria-label=Header> <a href=https://books.japila.pl/apache-spark-internals title="The Internals of Apache Spark" class="md-header-nav__button md-logo" aria-label="The Internals of Apache Spark"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M19 2l-5 4.5v11l5-4.5V2M6.5 5C4.55 5 2.45 5.4 1 6.5v14.66c0 .25.25.5.5.5.1 0 .15-.07.25-.07 1.35-.65 3.3-1.09 4.75-1.09 1.95 0 4.05.4 5.5 1.5 1.35-.85 3.8-1.5 5.5-1.5 1.65 0 3.35.31 4.75 1.06.1.05.15.03.25.03.25 0 .5-.25.5-.5V6.5c-.6-.45-1.25-.75-2-1V19c-1.1-.35-2.3-.5-3.5-.5-1.7 0-4.15.65-5.5 1.5V6.5C10.55 5.4 8.45 5 6.5 5z"/></svg> </a> <label class="md-header-nav__button md-icon" for=__drawer> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2z"/></svg> </label> <div class=md-header-nav__title data-md-component=header-title> <div class=md-header-nav__ellipsis> <span class="md-header-nav__topic md-ellipsis"> The Internals of Apache Spark </span> <span class="md-header-nav__topic md-ellipsis"> DAGScheduler </span> </div> </div> <label class="md-header-nav__button md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0116 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 019.5 16 6.5 6.5 0 013 9.5 6.5 6.5 0 019.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5z"/></svg> </label> <div class=md-search data-md-component=search role=dialog> <label class=md-search__overlay for=__search></label> <div class=md-search__inner role=search> <form class=md-search__form name=search> <input type=text class=md-search__input name=query aria-label=Search placeholder=Search autocapitalize=off autocorrect=off autocomplete=off spellcheck=false data-md-component=search-query data-md-state=active> <label class="md-search__icon md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0116 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 019.5 16 6.5 6.5 0 013 9.5 6.5 6.5 0 019.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5z"/></svg> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg> </label> <button type=reset class="md-search__icon md-icon" aria-label=Clear data-md-component=search-reset tabindex=-1> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M19 6.41L17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41z"/></svg> </button> </form> <div class=md-search__output> <div class=md-search__scrollwrap data-md-scrollfix> <div class=md-search-result data-md-component=search-result> <div class=md-search-result__meta> Initializing search </div> <ol class=md-search-result__list></ol> </div> </div> </div> </div> </div> <div class=md-header-nav__source> <a href=https://github.com/japila-books/apache-spark-internals/ title="Go to repository" class=md-source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 496 512"><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg> </div> <div class=md-source__repository> apache-spark-internals </div> </a> </div> </nav> </header> <div class=md-container data-md-component=container> <nav class="md-tabs md-tabs--active" aria-label=Tabs data-md-component=tabs> <div class="md-tabs__inner md-grid"> <ul class=md-tabs__list> <li class=md-tabs__item> <a href=../.. class="md-tabs__link md-tabs__link--active"> Home </a> </li> <li class=md-tabs__item> <a href=../../spark-logging/ class=md-tabs__link> Monitoring </a> </li> <li class=md-tabs__item> <a href=../../tools/spark-shell/ class=md-tabs__link> Tools </a> </li> <li class=md-tabs__item> <a href=../../rdd/ class=md-tabs__link> RDD </a> </li> <li class=md-tabs__item> <a href=../../metrics/ class=md-tabs__link> Metrics </a> </li> <li class=md-tabs__item> <a href=../../demo/diskblockmanager-and-block-data/ class=md-tabs__link> Demos </a> </li> <li class=md-tabs__item> <a href=../../exercises/spark-exercise-pairrddfunctions-oneliners/ class=md-tabs__link> Exercises </a> </li> <li class=md-tabs__item> <a href=../../webui/ class=md-tabs__link> Web UI </a> </li> </ul> </div> </nav> <main class=md-main data-md-component=main> <div class="md-main__inner md-grid"> <div class="md-sidebar md-sidebar--primary" data-md-component=navigation> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--primary" aria-label=Navigation data-md-level=0> <label class=md-nav__title for=__drawer> <a href=https://books.japila.pl/apache-spark-internals title="The Internals of Apache Spark" class="md-nav__button md-logo" aria-label="The Internals of Apache Spark"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M19 2l-5 4.5v11l5-4.5V2M6.5 5C4.55 5 2.45 5.4 1 6.5v14.66c0 .25.25.5.5.5.1 0 .15-.07.25-.07 1.35-.65 3.3-1.09 4.75-1.09 1.95 0 4.05.4 5.5 1.5 1.35-.85 3.8-1.5 5.5-1.5 1.65 0 3.35.31 4.75 1.06.1.05.15.03.25.03.25 0 .5-.25.5-.5V6.5c-.6-.45-1.25-.75-2-1V19c-1.1-.35-2.3-.5-3.5-.5-1.7 0-4.15.65-5.5 1.5V6.5C10.55 5.4 8.45 5 6.5 5z"/></svg> </a> The Internals of Apache Spark </label> <div class=md-nav__source> <a href=https://github.com/japila-books/apache-spark-internals/ title="Go to repository" class=md-source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 496 512"><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg> </div> <div class=md-source__repository> apache-spark-internals </div> </a> </div> <ul class=md-nav__list data-md-scrollfix> <li class="md-nav__item md-nav__item--active md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-1 type=checkbox id=nav-1 checked> <label class=md-nav__link for=nav-1> Home <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label=Home data-md-level=1> <label class=md-nav__title for=nav-1> <span class="md-nav__icon md-icon"></span> Home </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../.. class=md-nav__link> Welcome </a> </li> <li class=md-nav__item> <a href=../../overview/ class=md-nav__link> Overview </a> </li> <li class=md-nav__item> <a href=../../SparkEnv/ class=md-nav__link> SparkEnv </a> </li> <li class=md-nav__item> <a href=../../SparkConf/ class=md-nav__link> SparkConf </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-1-5 type=checkbox id=nav-1-5> <label class=md-nav__link for=nav-1-5> SparkContext <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label=SparkContext data-md-level=2> <label class=md-nav__title for=nav-1-5> <span class="md-nav__icon md-icon"></span> SparkContext </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../SparkContext/ class=md-nav__link> SparkContext </a> </li> <li class=md-nav__item> <a href=../../SparkContext-creating-instance-internals/ class=md-nav__link> Inside Creating SparkContext </a> </li> <li class=md-nav__item> <a href=../../spark-HeartbeatReceiver/ class=md-nav__link> HeartbeatReceiver RPC Endpoint </a> </li> <li class=md-nav__item> <a href=../../spark-sparkcontext-ConsoleProgressBar/ class=md-nav__link> ConsoleProgressBar </a> </li> <li class=md-nav__item> <a href=../../spark-sparkcontext-SparkStatusTracker/ class=md-nav__link> SparkStatusTracker </a> </li> <li class=md-nav__item> <a href=../../spark-sparkcontext-local-properties/ class=md-nav__link> Local Properties </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../../configuration-properties/ class=md-nav__link> Configuration Properties </a> </li> <li class=md-nav__item> <a href=../../spark-properties/ class=md-nav__link> Spark Properties </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-1-8 type=checkbox id=nav-1-8> <label class=md-nav__link for=nav-1-8> Shuffle System <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label="Shuffle System" data-md-level=2> <label class=md-nav__title for=nav-1-8> <span class="md-nav__icon md-icon"></span> Shuffle System </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../shuffle/ class=md-nav__link> Shuffle System </a> </li> <li class=md-nav__item> <a href=../../shuffle/ShuffleManager/ class=md-nav__link> ShuffleManager </a> </li> <li class=md-nav__item> <a href=../../shuffle/SortShuffleManager/ class=md-nav__link> SortShuffleManager </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-1-8-4 type=checkbox id=nav-1-8-4> <label class=md-nav__link for=nav-1-8-4> Shuffle Handlers <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label="Shuffle Handlers" data-md-level=3> <label class=md-nav__title for=nav-1-8-4> <span class="md-nav__icon md-icon"></span> Shuffle Handlers </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../shuffle/ShuffleHandle/ class=md-nav__link> ShuffleHandle </a> </li> <li class=md-nav__item> <a href=../../shuffle/BaseShuffleHandle/ class=md-nav__link> BaseShuffleHandle </a> </li> <li class=md-nav__item> <a href=../../shuffle/BypassMergeSortShuffleHandle/ class=md-nav__link> BypassMergeSortShuffleHandle </a> </li> <li class=md-nav__item> <a href=../../shuffle/SerializedShuffleHandle/ class=md-nav__link> SerializedShuffleHandle </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-1-8-5 type=checkbox id=nav-1-8-5> <label class=md-nav__link for=nav-1-8-5> Shuffle Readers <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label="Shuffle Readers" data-md-level=3> <label class=md-nav__title for=nav-1-8-5> <span class="md-nav__icon md-icon"></span> Shuffle Readers </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../shuffle/ShuffleReader/ class=md-nav__link> ShuffleReader </a> </li> <li class=md-nav__item> <a href=../../shuffle/BlockStoreShuffleReader/ class=md-nav__link> BlockStoreShuffleReader </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-1-8-6 type=checkbox id=nav-1-8-6> <label class=md-nav__link for=nav-1-8-6> Shuffle Writers <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label="Shuffle Writers" data-md-level=3> <label class=md-nav__title for=nav-1-8-6> <span class="md-nav__icon md-icon"></span> Shuffle Writers </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../shuffle/ShuffleWriter/ class=md-nav__link> ShuffleWriter </a> </li> <li class=md-nav__item> <a href=../../shuffle/BypassMergeSortShuffleWriter/ class=md-nav__link> BypassMergeSortShuffleWriter </a> </li> <li class=md-nav__item> <a href=../../shuffle/SortShuffleWriter/ class=md-nav__link> SortShuffleWriter </a> </li> <li class=md-nav__item> <a href=../../shuffle/UnsafeShuffleWriter/ class=md-nav__link> UnsafeShuffleWriter </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../../shuffle/ShuffleExternalSorter/ class=md-nav__link> ShuffleExternalSorter </a> </li> <li class=md-nav__item> <a href=../../shuffle/ShuffleInMemorySorter/ class=md-nav__link> ShuffleInMemorySorter </a> </li> <li class=md-nav__item> <a href=../../shuffle/ShuffleBlockResolver/ class=md-nav__link> ShuffleBlockResolver </a> </li> <li class=md-nav__item> <a href=../../shuffle/IndexShuffleBlockResolver/ class=md-nav__link> IndexShuffleBlockResolver </a> </li> <li class=md-nav__item> <a href=../../shuffle/FetchFailedException/ class=md-nav__link> FetchFailedException </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-1-8-12 type=checkbox id=nav-1-8-12> <label class=md-nav__link for=nav-1-8-12> Spillable Collections <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label="Spillable Collections" data-md-level=3> <label class=md-nav__title for=nav-1-8-12> <span class="md-nav__icon md-icon"></span> Spillable Collections </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../shuffle/Spillable/ class=md-nav__link> Spillable </a> </li> <li class=md-nav__item> <a href=../../shuffle/ExternalAppendOnlyMap/ class=md-nav__link> ExternalAppendOnlyMap </a> </li> <li class=md-nav__item> <a href=../../shuffle/ExternalSorter/ class=md-nav__link> ExternalSorter </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../../shuffle/ShuffleWriteProcessor/ class=md-nav__link> ShuffleWriteProcessor </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../../spark-deploy-mode/ class=md-nav__link> Deploy Mode </a> </li> <li class=md-nav__item> <a href=../../rdd-checkpointing/ class=md-nav__link> RDD Checkpointing </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-1-11 type=checkbox id=nav-1-11> <label class=md-nav__link for=nav-1-11> Dynamic Allocation of Executors <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label="Dynamic Allocation of Executors" data-md-level=2> <label class=md-nav__title for=nav-1-11> <span class="md-nav__icon md-icon"></span> Dynamic Allocation of Executors </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../spark-dynamic-allocation/ class=md-nav__link> Dynamic Allocation of Executors </a> </li> <li class=md-nav__item> <a href=../../ExecutorAllocationManager/ class=md-nav__link> ExecutorAllocationManager </a> </li> <li class=md-nav__item> <a href=../../ExecutorAllocationClient/ class=md-nav__link> ExecutorAllocationClient </a> </li> <li class=md-nav__item> <a href=../../ExecutorAllocationManagerSource/ class=md-nav__link> ExecutorAllocationManagerSource </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../../speculative-execution-of-tasks/ class=md-nav__link> Speculative Execution of Tasks </a> </li> <li class=md-nav__item> <a href=../../CompressionCodec/ class=md-nav__link> CompressionCodec </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-1-14 type=checkbox id=nav-1-14> <label class=md-nav__link for=nav-1-14> Network <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label=Network data-md-level=2> <label class=md-nav__title for=nav-1-14> <span class="md-nav__icon md-icon"></span> Network </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../network/TransportContext/ class=md-nav__link> TransportContext </a> </li> <li class=md-nav__item> <a href=../../network/MessageHandler/ class=md-nav__link> MessageHandler </a> </li> <li class=md-nav__item> <a href=../../network/TransportRequestHandler/ class=md-nav__link> TransportRequestHandler </a> </li> <li class=md-nav__item> <a href=../../network/TransportConf/ class=md-nav__link> TransportConf </a> </li> <li class=md-nav__item> <a href=../../network/SparkTransportConf/ class=md-nav__link> SparkTransportConf </a> </li> <li class=md-nav__item> <a href=../../network/TransportClientFactory/ class=md-nav__link> TransportClientFactory </a> </li> <li class=md-nav__item> <a href=../../network/TransportServer/ class=md-nav__link> TransportServer </a> </li> <li class=md-nav__item> <a href=../../network/RpcHandler/ class=md-nav__link> RpcHandler </a> </li> <li class=md-nav__item> <a href=../../network/StreamManager/ class=md-nav__link> StreamManager </a> </li> <li class=md-nav__item> <a href=../../network/OneForOneStreamManager/ class=md-nav__link> OneForOneStreamManager </a> </li> <li class=md-nav__item> <a href=../../network/ManagedBuffer/ class=md-nav__link> ManagedBuffer </a> </li> <li class=md-nav__item> <a href=../../network/RpcResponseCallback/ class=md-nav__link> RpcResponseCallback </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-1-15 type=checkbox id=nav-1-15> <label class=md-nav__link for=nav-1-15> Core <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label=Core data-md-level=2> <label class=md-nav__title for=nav-1-15> <span class="md-nav__icon md-icon"></span> Core </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../core/BroadcastManager/ class=md-nav__link> BroadcastManager </a> </li> <li class=md-nav__item> <a href=../../core/BroadcastFactory/ class=md-nav__link> BroadcastFactory </a> </li> <li class=md-nav__item> <a href=../../core/TorrentBroadcastFactory/ class=md-nav__link> TorrentBroadcastFactory </a> </li> <li class=md-nav__item> <a href=../../core/TorrentBroadcast/ class=md-nav__link> TorrentBroadcast </a> </li> <li class=md-nav__item> <a href=../../core/ContextCleaner/ class=md-nav__link> ContextCleaner </a> </li> <li class=md-nav__item> <a href=../../core/CleanerListener/ class=md-nav__link> CleanerListener </a> </li> <li class=md-nav__item> <a href=../../core/BlockFetchingListener/ class=md-nav__link> BlockFetchingListener </a> </li> <li class=md-nav__item> <a href=../../core/RetryingBlockFetcher/ class=md-nav__link> RetryingBlockFetcher </a> </li> <li class=md-nav__item> <a href=../../core/BlockFetchStarter/ class=md-nav__link> BlockFetchStarter </a> </li> <li class=md-nav__item> <a href=../../core/AppStatusListener/ class=md-nav__link> AppStatusListener </a> </li> <li class=md-nav__item> <a href=../../core/AppStatusStore/ class=md-nav__link> AppStatusStore </a> </li> <li class=md-nav__item> <a href=../../core/KVStore/ class=md-nav__link> KVStore </a> </li> <li class=md-nav__item> <a href=../../core/ElementTrackingStore/ class=md-nav__link> ElementTrackingStore </a> </li> <li class=md-nav__item> <a href=../../core/InMemoryStore/ class=md-nav__link> InMemoryStore </a> </li> <li class=md-nav__item> <a href=../../core/LevelDB/ class=md-nav__link> LevelDB </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--active md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-1-16 type=checkbox id=nav-1-16 checked> <label class=md-nav__link for=nav-1-16> Scheduler <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label=Scheduler data-md-level=2> <label class=md-nav__title for=nav-1-16> <span class="md-nav__icon md-icon"></span> Scheduler </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../ class=md-nav__link> Spark Scheduler </a> </li> <li class="md-nav__item md-nav__item--active"> <input class="md-nav__toggle md-toggle" data-md-toggle=toc type=checkbox id=__toc> <a href=./ class="md-nav__link md-nav__link--active"> DAGScheduler </a> </li> <li class=md-nav__item> <a href=../DAGSchedulerEvent/ class=md-nav__link> DAGSchedulerEvent </a> </li> <li class=md-nav__item> <a href=../DAGSchedulerEventProcessLoop/ class=md-nav__link> DAGSchedulerEventProcessLoop </a> </li> <li class=md-nav__item> <a href=../Stage/ class=md-nav__link> Stage </a> </li> <li class=md-nav__item> <a href=../ResultStage/ class=md-nav__link> ResultStage </a> </li> <li class=md-nav__item> <a href=../ShuffleMapStage/ class=md-nav__link> ShuffleMapStage </a> </li> <li class=md-nav__item> <a href=../MapOutputTracker/ class=md-nav__link> MapOutputTracker </a> </li> <li class=md-nav__item> <a href=../MapOutputTrackerMaster/ class=md-nav__link> MapOutputTrackerMaster </a> </li> <li class=md-nav__item> <a href=../ShuffleStatus/ class=md-nav__link> ShuffleStatus </a> </li> <li class=md-nav__item> <a href=../MapOutputTrackerMasterEndpoint/ class=md-nav__link> MapOutputTrackerMasterEndpoint </a> </li> <li class=md-nav__item> <a href=../MapOutputTrackerWorker/ class=md-nav__link> MapOutputTrackerWorker </a> </li> <li class=md-nav__item> <a href=../spark-scheduler-StageInfo/ class=md-nav__link> StageInfo </a> </li> <li class=md-nav__item> <a href=../spark-scheduler-JobListener/ class=md-nav__link> JobListener </a> </li> <li class=md-nav__item> <a href=../spark-scheduler-JobWaiter/ class=md-nav__link> JobWaiter </a> </li> <li class=md-nav__item> <a href=../TaskScheduler/ class=md-nav__link> TaskScheduler </a> </li> <li class=md-nav__item> <a href=../TaskSchedulerImpl/ class=md-nav__link> TaskSchedulerImpl </a> </li> <li class=md-nav__item> <a href=../SchedulerBackend/ class=md-nav__link> SchedulerBackend </a> </li> <li class=md-nav__item> <a href=../CoarseGrainedSchedulerBackend/ class=md-nav__link> CoarseGrainedSchedulerBackend </a> </li> <li class=md-nav__item> <a href=../CoarseGrainedSchedulerBackend-DriverEndpoint/ class=md-nav__link> DriverEndpoint </a> </li> <li class=md-nav__item> <a href=../Task/ class=md-nav__link> Task </a> </li> <li class=md-nav__item> <a href=../ShuffleMapTask/ class=md-nav__link> ShuffleMapTask </a> </li> <li class=md-nav__item> <a href=../ResultTask/ class=md-nav__link> ResultTask </a> </li> <li class=md-nav__item> <a href=../TaskSet/ class=md-nav__link> TaskSet </a> </li> <li class=md-nav__item> <a href=../TaskSetManager/ class=md-nav__link> TaskSetManager </a> </li> <li class=md-nav__item> <a href=../ActiveJob/ class=md-nav__link> ActiveJob </a> </li> <li class=md-nav__item> <a href=../SchedulableBuilder/ class=md-nav__link> SchedulableBuilder </a> </li> <li class=md-nav__item> <a href=../FIFOSchedulableBuilder/ class=md-nav__link> FIFOSchedulableBuilder </a> </li> <li class=md-nav__item> <a href=../FairSchedulableBuilder/ class=md-nav__link> FairSchedulableBuilder </a> </li> <li class=md-nav__item> <a href=../Schedulable/ class=md-nav__link> Schedulable </a> </li> <li class=md-nav__item> <a href=../Pool/ class=md-nav__link> Pool </a> </li> <li class=md-nav__item> <a href=../SchedulingMode/ class=md-nav__link> SchedulingMode </a> </li> <li class=md-nav__item> <a href=../TaskInfo/ class=md-nav__link> TaskInfo </a> </li> <li class=md-nav__item> <a href=../MapStatus/ class=md-nav__link> MapStatus </a> </li> <li class=md-nav__item> <a href=../TaskDescription/ class=md-nav__link> TaskDescription </a> </li> <li class=md-nav__item> <a href=../TaskResultGetter/ class=md-nav__link> TaskResultGetter </a> </li> <li class=md-nav__item> <a href=../TaskContext/ class=md-nav__link> TaskContext </a> </li> <li class=md-nav__item> <a href=../BarrierTaskContext/ class=md-nav__link> BarrierTaskContext </a> </li> <li class=md-nav__item> <a href=../TaskContextImpl/ class=md-nav__link> TaskContextImpl </a> </li> <li class=md-nav__item> <a href=../TaskResult/ class=md-nav__link> TaskResult </a> </li> <li class=md-nav__item> <a href=../TaskSetBlacklist/ class=md-nav__link> TaskSetBlacklist </a> </li> <li class=md-nav__item> <a href=../OutputCommitCoordinator/ class=md-nav__link> OutputCommitCoordinator </a> </li> <li class=md-nav__item> <a href=../TaskLocation/ class=md-nav__link> TaskLocation </a> </li> <li class=md-nav__item> <a href=../ExternalClusterManager/ class=md-nav__link> ExternalClusterManager </a> </li> <li class=md-nav__item> <a href=../LiveListenerBus/ class=md-nav__link> LiveListenerBus </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-1-17 type=checkbox id=nav-1-17> <label class=md-nav__link for=nav-1-17> RPC <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label=RPC data-md-level=2> <label class=md-nav__title for=nav-1-17> <span class="md-nav__icon md-icon"></span> RPC </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../rpc/ class=md-nav__link> RPC System </a> </li> <li class=md-nav__item> <a href=../../rpc/RpcEnv/ class=md-nav__link> RpcEnv </a> </li> <li class=md-nav__item> <a href=../../rpc/NettyRpcEnv/ class=md-nav__link> NettyRpcEnv </a> </li> <li class=md-nav__item> <a href=../../rpc/NettyStreamManager/ class=md-nav__link> NettyStreamManager </a> </li> <li class=md-nav__item> <a href=../../rpc/RpcEnvConfig/ class=md-nav__link> RpcEnvConfig </a> </li> <li class=md-nav__item> <a href=../../rpc/RpcEndpoint/ class=md-nav__link> RpcEndpoint </a> </li> <li class=md-nav__item> <a href=../../rpc/RpcEndpointRef/ class=md-nav__link> RpcEndpointRef </a> </li> <li class=md-nav__item> <a href=../../rpc/RpcAddress/ class=md-nav__link> RpcAddress </a> </li> <li class=md-nav__item> <a href=../../rpc/RpcEndpointAddress/ class=md-nav__link> RpcEndpointAddress </a> </li> <li class=md-nav__item> <a href=../../rpc/RpcEnvFactory/ class=md-nav__link> RpcEnvFactory </a> </li> <li class=md-nav__item> <a href=../../rpc/NettyRpcEnvFactory/ class=md-nav__link> NettyRpcEnvFactory </a> </li> <li class=md-nav__item> <a href=../../rpc/RpcEnvFileServer/ class=md-nav__link> RpcEnvFileServer </a> </li> <li class=md-nav__item> <a href=../../rpc/spark-rpc-netty/ class=md-nav__link> spark-rpc-netty </a> </li> <li class=md-nav__item> <a href=../../rpc/RpcUtils/ class=md-nav__link> RpcUtils </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-1-18 type=checkbox id=nav-1-18> <label class=md-nav__link for=nav-1-18> Memory <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label=Memory data-md-level=2> <label class=md-nav__title for=nav-1-18> <span class="md-nav__icon md-icon"></span> Memory </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../memory/ class=md-nav__link> Memory System </a> </li> <li class=md-nav__item> <a href=../../memory/MemoryManager/ class=md-nav__link> MemoryManager </a> </li> <li class=md-nav__item> <a href=../../memory/StaticMemoryManager/ class=md-nav__link> StaticMemoryManager </a> </li> <li class=md-nav__item> <a href=../../memory/UnifiedMemoryManager/ class=md-nav__link> UnifiedMemoryManager </a> </li> <li class=md-nav__item> <a href=../../memory/MemoryPool/ class=md-nav__link> MemoryPool </a> </li> <li class=md-nav__item> <a href=../../memory/ExecutionMemoryPool/ class=md-nav__link> ExecutionMemoryPool </a> </li> <li class=md-nav__item> <a href=../../memory/StorageMemoryPool/ class=md-nav__link> StorageMemoryPool </a> </li> <li class=md-nav__item> <a href=../../memory/TaskMemoryManager/ class=md-nav__link> TaskMemoryManager </a> </li> <li class=md-nav__item> <a href=../../memory/MemoryConsumer/ class=md-nav__link> MemoryConsumer </a> </li> <li class=md-nav__item> <a href=../../memory/BytesToBytesMap/ class=md-nav__link> BytesToBytesMap </a> </li> <li class=md-nav__item> <a href=../../memory/UnsafeSorterSpillReader/ class=md-nav__link> UnsafeSorterSpillReader </a> </li> <li class=md-nav__item> <a href=../../memory/UnsafeExternalSorter/ class=md-nav__link> UnsafeExternalSorter </a> </li> <li class=md-nav__item> <a href=../../memory/UnsafeInMemorySorter/ class=md-nav__link> UnsafeInMemorySorter </a> </li> <li class=md-nav__item> <a href=../../memory/UnsafeSorterSpillWriter/ class=md-nav__link> UnsafeSorterSpillWriter </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-1-19 type=checkbox id=nav-1-19> <label class=md-nav__link for=nav-1-19> Storage <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label=Storage data-md-level=2> <label class=md-nav__title for=nav-1-19> <span class="md-nav__icon md-icon"></span> Storage </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../storage/BlockManager/ class=md-nav__link> BlockManager </a> </li> <li class=md-nav__item> <a href=../../storage/BlockManagerId/ class=md-nav__link> BlockManagerId </a> </li> <li class=md-nav__item> <a href=../../storage/BlockManagerInfo/ class=md-nav__link> BlockManagerInfo </a> </li> <li class=md-nav__item> <a href=../../storage/BlockManagerMaster/ class=md-nav__link> BlockManagerMaster </a> </li> <li class=md-nav__item> <a href=../../storage/BlockManagerMasterEndpoint/ class=md-nav__link> BlockManagerMasterEndpoint </a> </li> <li class=md-nav__item> <a href=../../storage/BlockManagerSlaveEndpoint/ class=md-nav__link> BlockManagerSlaveEndpoint </a> </li> <li class=md-nav__item> <a href=../../storage/BlockId/ class=md-nav__link> BlockId </a> </li> <li class=md-nav__item> <a href=../../storage/BlockDataManager/ class=md-nav__link> BlockDataManager </a> </li> <li class=md-nav__item> <a href=../../storage/DiskStore/ class=md-nav__link> DiskStore </a> </li> <li class=md-nav__item> <a href=../../storage/DiskBlockManager/ class=md-nav__link> DiskBlockManager </a> </li> <li class=md-nav__item> <a href=../../storage/MemoryStore/ class=md-nav__link> MemoryStore </a> </li> <li class=md-nav__item> <a href=../../storage/BlockEvictionHandler/ class=md-nav__link> BlockEvictionHandler </a> </li> <li class=md-nav__item> <a href=../../storage/BlockData/ class=md-nav__link> BlockData </a> </li> <li class=md-nav__item> <a href=../../storage/BlockInfoManager/ class=md-nav__link> BlockInfoManager </a> </li> <li class=md-nav__item> <a href=../../storage/BlockInfo/ class=md-nav__link> BlockInfo </a> </li> <li class=md-nav__item> <a href=../../storage/DiskBlockObjectWriter/ class=md-nav__link> DiskBlockObjectWriter </a> </li> <li class=md-nav__item> <a href=../../storage/BlockManagerSource/ class=md-nav__link> BlockManagerSource </a> </li> <li class=md-nav__item> <a href=../../storage/ShuffleMetricsSource/ class=md-nav__link> ShuffleMetricsSource </a> </li> <li class=md-nav__item> <a href=../../storage/ShuffleClient/ class=md-nav__link> ShuffleClient </a> </li> <li class=md-nav__item> <a href=../../storage/BlockTransferService/ class=md-nav__link> BlockTransferService </a> </li> <li class=md-nav__item> <a href=../../storage/NettyBlockTransferService/ class=md-nav__link> NettyBlockTransferService </a> </li> <li class=md-nav__item> <a href=../../storage/NettyBlockRpcServer/ class=md-nav__link> NettyBlockRpcServer </a> </li> <li class=md-nav__item> <a href=../../storage/ExternalShuffleClient/ class=md-nav__link> ExternalShuffleClient </a> </li> <li class=md-nav__item> <a href=../../storage/OneForOneBlockFetcher/ class=md-nav__link> OneForOneBlockFetcher </a> </li> <li class=md-nav__item> <a href=../../storage/ShuffleBlockFetcherIterator/ class=md-nav__link> ShuffleBlockFetcherIterator </a> </li> <li class=md-nav__item> <a href=../../storage/RDDInfo/ class=md-nav__link> RDDInfo </a> </li> <li class=md-nav__item> <a href=../../storage/StorageLevel/ class=md-nav__link> StorageLevel </a> </li> <li class=md-nav__item> <a href=../../storage/StorageStatus/ class=md-nav__link> StorageStatus </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-1-20 type=checkbox id=nav-1-20> <label class=md-nav__link for=nav-1-20> Serialization <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label=Serialization data-md-level=2> <label class=md-nav__title for=nav-1-20> <span class="md-nav__icon md-icon"></span> Serialization </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../serializer/ class=md-nav__link> Serialization System </a> </li> <li class=md-nav__item> <a href=../../serializer/SerializerManager/ class=md-nav__link> SerializerManager </a> </li> <li class=md-nav__item> <a href=../../serializer/Serializer/ class=md-nav__link> Serializer </a> </li> <li class=md-nav__item> <a href=../../serializer/SerializerInstance/ class=md-nav__link> SerializerInstance </a> </li> <li class=md-nav__item> <a href=../../serializer/SerializationStream/ class=md-nav__link> SerializationStream </a> </li> <li class=md-nav__item> <a href=../../serializer/DeserializationStream/ class=md-nav__link> DeserializationStream </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-1-21 type=checkbox id=nav-1-21> <label class=md-nav__link for=nav-1-21> Deploy <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label=Deploy data-md-level=2> <label class=md-nav__title for=nav-1-21> <span class="md-nav__icon md-icon"></span> Deploy </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../deploy/ExternalShuffleService/ class=md-nav__link> ExternalShuffleService </a> </li> <li class=md-nav__item> <a href=../../deploy/ExternalShuffleBlockHandler/ class=md-nav__link> ExternalShuffleBlockHandler </a> </li> <li class=md-nav__item> <a href=../../deploy/ExternalShuffleBlockResolver/ class=md-nav__link> ExternalShuffleBlockResolver </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-1-22 type=checkbox id=nav-1-22> <label class=md-nav__link for=nav-1-22> Executor <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label=Executor data-md-level=2> <label class=md-nav__title for=nav-1-22> <span class="md-nav__icon md-icon"></span> Executor </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../executor/Executor/ class=md-nav__link> Executor </a> </li> <li class=md-nav__item> <a href=../../executor/TaskRunner/ class=md-nav__link> TaskRunner </a> </li> <li class=md-nav__item> <a href=../../executor/ExecutorSource/ class=md-nav__link> ExecutorSource </a> </li> <li class=md-nav__item> <a href=../../executor/ExecutorBackend/ class=md-nav__link> ExecutorBackend </a> </li> <li class=md-nav__item> <a href=../../executor/CoarseGrainedExecutorBackend/ class=md-nav__link> CoarseGrainedExecutorBackend </a> </li> <li class=md-nav__item> <a href=../../executor/TaskMetrics/ class=md-nav__link> TaskMetrics </a> </li> <li class=md-nav__item> <a href=../../executor/ShuffleWriteMetrics/ class=md-nav__link> ShuffleWriteMetrics </a> </li> <li class=md-nav__item> <a href=../../executor/ShuffleReadMetrics/ class=md-nav__link> ShuffleReadMetrics </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-1-23 type=checkbox id=nav-1-23> <label class=md-nav__link for=nav-1-23> Shared Variables <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label="Shared Variables" data-md-level=2> <label class=md-nav__title for=nav-1-23> <span class="md-nav__icon md-icon"></span> Shared Variables </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../Broadcast/ class=md-nav__link> Broadcast </a> </li> <li class=md-nav__item> <a href=../../accumulators/ class=md-nav__link> accumulators </a> </li> <li class=md-nav__item> <a href=../../AccumulatorContext/ class=md-nav__link> AccumulatorContext </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-1-24 type=checkbox id=nav-1-24> <label class=md-nav__link for=nav-1-24> Barrier Execution Mode <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label="Barrier Execution Mode" data-md-level=2> <label class=md-nav__title for=nav-1-24> <span class="md-nav__icon md-icon"></span> Barrier Execution Mode </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../barrier-execution-mode/ class=md-nav__link> barrier-execution-mode </a> </li> <li class=md-nav__item> <a href=../../RDDBarrier/ class=md-nav__link> RDDBarrier </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../../data-locality/ class=md-nav__link> Data Locality </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-1-26 type=checkbox id=nav-1-26> <label class=md-nav__link for=nav-1-26> Spark Deployment Architecture <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label="Spark Deployment Architecture" data-md-level=2> <label class=md-nav__title for=nav-1-26> <span class="md-nav__icon md-icon"></span> Spark Deployment Architecture </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../architecture/ class=md-nav__link> Architecture </a> </li> <li class=md-nav__item> <a href=../../driver/ class=md-nav__link> Driver </a> </li> <li class=md-nav__item> <a href=../../master/ class=md-nav__link> Master </a> </li> <li class=md-nav__item> <a href=../../workers/ class=md-nav__link> Workers </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-1-27 type=checkbox id=nav-1-27> <label class=md-nav__link for=nav-1-27> Internal IO <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label="Internal IO" data-md-level=2> <label class=md-nav__title for=nav-1-27> <span class="md-nav__icon md-icon"></span> Internal IO </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../SparkHadoopWriter/ class=md-nav__link> SparkHadoopWriter </a> </li> <li class=md-nav__item> <a href=../../FileCommitProtocol/ class=md-nav__link> FileCommitProtocol </a> </li> <li class=md-nav__item> <a href=../../HadoopMapReduceCommitProtocol/ class=md-nav__link> HadoopMapReduceCommitProtocol </a> </li> <li class=md-nav__item> <a href=../../HadoopMapRedCommitProtocol/ class=md-nav__link> HadoopMapRedCommitProtocol </a> </li> <li class=md-nav__item> <a href=../../HadoopWriteConfigUtil/ class=md-nav__link> HadoopWriteConfigUtil </a> </li> <li class=md-nav__item> <a href=../../HadoopMapReduceWriteConfigUtil/ class=md-nav__link> HadoopMapReduceWriteConfigUtil </a> </li> <li class=md-nav__item> <a href=../../HadoopMapRedWriteConfigUtil/ class=md-nav__link> HadoopMapRedWriteConfigUtil </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-1-28 type=checkbox id=nav-1-28> <label class=md-nav__link for=nav-1-28> Misc <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label=Misc data-md-level=2> <label class=md-nav__title for=nav-1-28> <span class="md-nav__icon md-icon"></span> Misc </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../spark-deployment-environments/ class=md-nav__link> Deployment Environments </a> </li> <li class=md-nav__item> <a href=../../spark-building-from-sources/ class=md-nav__link> Building from Sources </a> </li> <li class=md-nav__item> <a href=../../AppStatusPlugin/ class=md-nav__link> AppStatusPlugin </a> </li> <li class=md-nav__item> <a href=../../KVStoreView/ class=md-nav__link> KVStoreView </a> </li> <li class=md-nav__item> <a href=../../InterruptibleIterator/ class=md-nav__link> InterruptibleIterator </a> </li> <li class=md-nav__item> <a href=../../Utils/ class=md-nav__link> Utils </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-1-29 type=checkbox id=nav-1-29> <label class=md-nav__link for=nav-1-29> Spark Tips and Tricks <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label="Spark Tips and Tricks" data-md-level=2> <label class=md-nav__title for=nav-1-29> <span class="md-nav__icon md-icon"></span> Spark Tips and Tricks </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../spark-tips-and-tricks/ class=md-nav__link> Spark Tips and Tricks </a> </li> <li class=md-nav__item> <a href=../../spark-tips-and-tricks-access-private-members-spark-shell/ class=md-nav__link> Access private members in Scala in Spark shell </a> </li> <li class=md-nav__item> <a href=../../spark-tips-and-tricks-sparkexception-task-not-serializable/ class=md-nav__link> Task not serializable Exception </a> </li> <li class=md-nav__item> <a href=../../spark-tips-and-tricks-running-spark-windows/ class=md-nav__link> Running Spark Applications on Windows </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-1-30 type=checkbox id=nav-1-30> <label class=md-nav__link for=nav-1-30> Spark Local <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label="Spark Local" data-md-level=2> <label class=md-nav__title for=nav-1-30> <span class="md-nav__icon md-icon"></span> Spark Local </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../local/ class=md-nav__link> Spark Local </a> </li> <li class=md-nav__item> <a href=../../local/LocalSchedulerBackend/ class=md-nav__link> LocalSchedulerBackend </a> </li> <li class=md-nav__item> <a href=../../local/LocalEndpoint/ class=md-nav__link> LocalEndpoint </a> </li> <li class=md-nav__item> <a href=../../local/LauncherBackend/ class=md-nav__link> LauncherBackend </a> </li> </ul> </nav> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-2 type=checkbox id=nav-2> <label class=md-nav__link for=nav-2> Monitoring <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label=Monitoring data-md-level=1> <label class=md-nav__title for=nav-2> <span class="md-nav__icon md-icon"></span> Monitoring </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../spark-logging/ class=md-nav__link> Logging </a> </li> <li class=md-nav__item> <a href=../../SparkListenerBus/ class=md-nav__link> SparkListenerBus </a> </li> <li class=md-nav__item> <a href=../../SparkListener/ class=md-nav__link> SparkListener </a> </li> <li class=md-nav__item> <a href=../../ExecutorAllocationListener/ class=md-nav__link> ExecutorAllocationListener </a> </li> <li class=md-nav__item> <a href=../../SpillListener/ class=md-nav__link> SpillListener </a> </li> <li class=md-nav__item> <a href=../../StatsReportListener/ class=md-nav__link> StatsReportListener </a> </li> <li class=md-nav__item> <a href=../../AsyncEventQueue/ class=md-nav__link> AsyncEventQueue </a> </li> <li class=md-nav__item> <a href=../../spark-debugging/ class=md-nav__link> spark-debugging </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-2-9 type=checkbox id=nav-2-9> <label class=md-nav__link for=nav-2-9> Spark History Server <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label="Spark History Server" data-md-level=2> <label class=md-nav__title for=nav-2-9> <span class="md-nav__icon md-icon"></span> Spark History Server </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../history-server/ class=md-nav__link> Spark History Server </a> </li> <li class=md-nav__item> <a href=../../history-server/configuration-properties/ class=md-nav__link> Configuration Properties </a> </li> <li class=md-nav__item> <a href=../../history-server/HistoryServer/ class=md-nav__link> HistoryServer </a> </li> <li class=md-nav__item> <a href=../../history-server/EventLoggingListener/ class=md-nav__link> EventLoggingListener </a> </li> <li class=md-nav__item> <a href=../../history-server/SQLHistoryListener/ class=md-nav__link> SQLHistoryListener </a> </li> <li class=md-nav__item> <a href=../../history-server/ApplicationHistoryProvider/ class=md-nav__link> ApplicationHistoryProvider </a> </li> <li class=md-nav__item> <a href=../../history-server/FsHistoryProvider/ class=md-nav__link> FsHistoryProvider </a> </li> <li class=md-nav__item> <a href=../../history-server/HistoryServerArguments/ class=md-nav__link> HistoryServerArguments </a> </li> <li class=md-nav__item> <a href=../../history-server/ApplicationCacheOperations/ class=md-nav__link> ApplicationCacheOperations </a> </li> <li class=md-nav__item> <a href=../../history-server/ApplicationCache/ class=md-nav__link> ApplicationCache </a> </li> <li class=md-nav__item> <a href=../../history-server/ReplayListenerBus/ class=md-nav__link> ReplayListenerBus </a> </li> <li class=md-nav__item> <a href=../../history-server/JsonProtocol/ class=md-nav__link> JsonProtocol </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-2-10 type=checkbox id=nav-2-10> <label class=md-nav__link for=nav-2-10> Status REST API <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label="Status REST API" data-md-level=2> <label class=md-nav__title for=nav-2-10> <span class="md-nav__icon md-icon"></span> Status REST API </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../rest/ class=md-nav__link> Status REST API </a> </li> <li class=md-nav__item> <a href=../../rest/ApiRootResource/ class=md-nav__link> ApiRootResource </a> </li> <li class=md-nav__item> <a href=../../rest/ApplicationListResource/ class=md-nav__link> ApplicationListResource </a> </li> <li class=md-nav__item> <a href=../../rest/OneApplicationResource/ class=md-nav__link> OneApplicationResource </a> </li> <li class=md-nav__item> <a href=../../rest/StagesResource/ class=md-nav__link> StagesResource </a> </li> <li class=md-nav__item> <a href=../../rest/OneApplicationAttemptResource/ class=md-nav__link> OneApplicationAttemptResource </a> </li> <li class=md-nav__item> <a href=../../rest/AbstractApplicationResource/ class=md-nav__link> AbstractApplicationResource </a> </li> <li class=md-nav__item> <a href=../../rest/BaseAppResource/ class=md-nav__link> BaseAppResource </a> </li> <li class=md-nav__item> <a href=../../rest/ApiRequestContext/ class=md-nav__link> ApiRequestContext </a> </li> <li class=md-nav__item> <a href=../../rest/UIRoot/ class=md-nav__link> UIRoot </a> </li> <li class=md-nav__item> <a href=../../rest/UIRootFromServletContext/ class=md-nav__link> UIRootFromServletContext </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-2-11 type=checkbox id=nav-2-11> <label class=md-nav__link for=nav-2-11> Plugin Framework <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label="Plugin Framework" data-md-level=2> <label class=md-nav__title for=nav-2-11> <span class="md-nav__icon md-icon"></span> Plugin Framework </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../plugins/ class=md-nav__link> Plugin Framework </a> </li> <li class=md-nav__item> <a href=../../plugins/PluginContainer/ class=md-nav__link> PluginContainer </a> </li> <li class=md-nav__item> <a href=../../plugins/DriverPluginContainer/ class=md-nav__link> DriverPluginContainer </a> </li> <li class=md-nav__item> <a href=../../plugins/ExecutorPluginContainer/ class=md-nav__link> ExecutorPluginContainer </a> </li> <li class=md-nav__item> <a href=../../plugins/SparkPlugin/ class=md-nav__link> SparkPlugin </a> </li> <li class=md-nav__item> <a href=../../plugins/DriverPlugin/ class=md-nav__link> DriverPlugin </a> </li> <li class=md-nav__item> <a href=../../plugins/ExecutorPlugin/ class=md-nav__link> ExecutorPlugin </a> </li> </ul> </nav> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-3 type=checkbox id=nav-3> <label class=md-nav__link for=nav-3> Tools <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label=Tools data-md-level=1> <label class=md-nav__title for=nav-3> <span class="md-nav__icon md-icon"></span> Tools </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../tools/spark-shell/ class=md-nav__link> spark-shell </a> </li> <li class=md-nav__item> <a href=../../tools/spark-submit/ class=md-nav__link> spark-submit </a> </li> <li class=md-nav__item> <a href=../../tools/spark-class/ class=md-nav__link> spark-class </a> </li> <li class=md-nav__item> <a href=../../tools/SparkLauncher/ class=md-nav__link> SparkLauncher </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-3-5 type=checkbox id=nav-3-5> <label class=md-nav__link for=nav-3-5> Internals <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label=Internals data-md-level=2> <label class=md-nav__title for=nav-3-5> <span class="md-nav__icon md-icon"></span> Internals </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../tools/SparkSubmitArguments/ class=md-nav__link> SparkSubmitArguments </a> </li> <li class=md-nav__item> <a href=../../tools/SparkSubmitOptionParser/ class=md-nav__link> SparkSubmitOptionParser </a> </li> <li class=md-nav__item> <a href=../../tools/SparkSubmitCommandBuilder/ class=md-nav__link> SparkSubmitCommandBuilder </a> </li> <li class=md-nav__item> <a href=../../tools/AbstractCommandBuilder/ class=md-nav__link> AbstractCommandBuilder </a> </li> </ul> </nav> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-4 type=checkbox id=nav-4> <label class=md-nav__link for=nav-4> RDD <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label=RDD data-md-level=1> <label class=md-nav__title for=nav-4> <span class="md-nav__icon md-icon"></span> RDD </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../rdd/ class=md-nav__link> Resilient Distributed Dataset </a> </li> <li class=md-nav__item> <a href=../../rdd/RDD/ class=md-nav__link> RDD </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-4-3 type=checkbox id=nav-4-3> <label class=md-nav__link for=nav-4-3> RDDs <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label=RDDs data-md-level=2> <label class=md-nav__title for=nav-4-3> <span class="md-nav__icon md-icon"></span> RDDs </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../rdd/CoGroupedRDD/ class=md-nav__link> CoGroupedRDD </a> </li> <li class=md-nav__item> <a href=../../rdd/spark-rdd-HadoopRDD/ class=md-nav__link> HadoopRDD </a> </li> <li class=md-nav__item> <a href=../../rdd/spark-rdd-MapPartitionsRDD/ class=md-nav__link> MapPartitionsRDD </a> </li> <li class=md-nav__item> <a href=../../rdd/spark-rdd-NewHadoopRDD/ class=md-nav__link> NewHadoopRDD </a> </li> <li class=md-nav__item> <a href=../../rdd/spark-rdd-OrderedRDDFunctions/ class=md-nav__link> OrderedRDDFunctions </a> </li> <li class=md-nav__item> <a href=../../rdd/spark-rdd-ParallelCollectionRDD/ class=md-nav__link> ParallelCollectionRDD </a> </li> <li class=md-nav__item> <a href=../../rdd/CheckpointRDD/ class=md-nav__link> CheckpointRDD </a> </li> <li class=md-nav__item> <a href=../../rdd/ReliableCheckpointRDD/ class=md-nav__link> ReliableCheckpointRDD </a> </li> <li class=md-nav__item> <a href=../../rdd/ShuffledRDD/ class=md-nav__link> ShuffledRDD </a> </li> <li class=md-nav__item> <a href=../../rdd/SubtractedRDD/ class=md-nav__link> SubtractedRDD </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-4-4 type=checkbox id=nav-4-4> <label class=md-nav__link for=nav-4-4> Operators <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label=Operators data-md-level=2> <label class=md-nav__title for=nav-4-4> <span class="md-nav__icon md-icon"></span> Operators </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../rdd/spark-rdd-operations/ class=md-nav__link> Operators </a> </li> <li class=md-nav__item> <a href=../../rdd/spark-rdd-transformations/ class=md-nav__link> Transformations </a> </li> <li class=md-nav__item> <a href=../../rdd/PairRDDFunctions/ class=md-nav__link> PairRDDFunctions </a> </li> <li class=md-nav__item> <a href=../../rdd/spark-rdd-actions/ class=md-nav__link> Actions </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../../rdd/Partitioner/ class=md-nav__link> Partitioner </a> </li> <li class=md-nav__item> <a href=../../rdd/spark-rdd-lineage/ class=md-nav__link> RDD Lineage </a> </li> <li class=md-nav__item> <a href=../../rdd/spark-rdd-caching/ class=md-nav__link> Caching and Persistence </a> </li> <li class=md-nav__item> <a href=../../rdd/spark-rdd-partitions/ class=md-nav__link> Partitions and Partitioning </a> </li> <li class=md-nav__item> <a href=../../rdd/spark-rdd-Partition/ class=md-nav__link> Partition </a> </li> <li class=md-nav__item> <a href=../../rdd/RDDCheckpointData/ class=md-nav__link> RDDCheckpointData </a> </li> <li class=md-nav__item> <a href=../../rdd/LocalRDDCheckpointData/ class=md-nav__link> LocalRDDCheckpointData </a> </li> <li class=md-nav__item> <a href=../../rdd/ReliableRDDCheckpointData/ class=md-nav__link> ReliableRDDCheckpointData </a> </li> <li class=md-nav__item> <a href=../../rdd/spark-rdd-shuffle/ class=md-nav__link> Shuffling </a> </li> <li class=md-nav__item> <a href=../../rdd/Dependency/ class=md-nav__link> Dependencies </a> </li> <li class=md-nav__item> <a href=../../rdd/NarrowDependency/ class=md-nav__link> NarrowDependency </a> </li> <li class=md-nav__item> <a href=../../rdd/ShuffleDependency/ class=md-nav__link> ShuffleDependency </a> </li> <li class=md-nav__item> <a href=../../rdd/Aggregator/ class=md-nav__link> Aggregator </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-4-18 type=checkbox id=nav-4-18> <label class=md-nav__link for=nav-4-18> Partitioners <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label=Partitioners data-md-level=2> <label class=md-nav__title for=nav-4-18> <span class="md-nav__icon md-icon"></span> Partitioners </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../rdd/HashPartitioner/ class=md-nav__link> HashPartitioner </a> </li> <li class=md-nav__item> <a href=../../rdd/RangePartitioner/ class=md-nav__link> RangePartitioner </a> </li> </ul> </nav> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-5 type=checkbox id=nav-5> <label class=md-nav__link for=nav-5> Metrics <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label=Metrics data-md-level=1> <label class=md-nav__title for=nav-5> <span class="md-nav__icon md-icon"></span> Metrics </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../metrics/ class=md-nav__link> Spark Metrics </a> </li> <li class=md-nav__item> <a href=../../metrics/configuration-properties/ class=md-nav__link> Configuration Properties </a> </li> <li class=md-nav__item> <a href=../../metrics/MetricsSystem/ class=md-nav__link> MetricsSystem </a> </li> <li class=md-nav__item> <a href=../../metrics/MetricsConfig/ class=md-nav__link> MetricsConfig </a> </li> <li class=md-nav__item> <a href=../../metrics/Source/ class=md-nav__link> Source </a> </li> <li class=md-nav__item> <a href=../../metrics/Sink/ class=md-nav__link> Sink </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-5-7 type=checkbox id=nav-5-7> <label class=md-nav__link for=nav-5-7> Sources <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label=Sources data-md-level=2> <label class=md-nav__title for=nav-5-7> <span class="md-nav__icon md-icon"></span> Sources </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../metrics/JvmSource/ class=md-nav__link> JvmSource </a> </li> <li class=md-nav__item> <a href=../../metrics/DAGSchedulerSource/ class=md-nav__link> DAGSchedulerSource </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-5-8 type=checkbox id=nav-5-8> <label class=md-nav__link for=nav-5-8> Sinks <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label=Sinks data-md-level=2> <label class=md-nav__title for=nav-5-8> <span class="md-nav__icon md-icon"></span> Sinks </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../metrics/MetricsServlet/ class=md-nav__link> MetricsServlet </a> </li> </ul> </nav> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-6 type=checkbox id=nav-6> <label class=md-nav__link for=nav-6> Demos <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label=Demos data-md-level=1> <label class=md-nav__title for=nav-6> <span class="md-nav__icon md-icon"></span> Demos </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../demo/diskblockmanager-and-block-data/ class=md-nav__link> DiskBlockManager and Block Data </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-7 type=checkbox id=nav-7> <label class=md-nav__link for=nav-7> Exercises <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label=Exercises data-md-level=1> <label class=md-nav__title for=nav-7> <span class="md-nav__icon md-icon"></span> Exercises </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../exercises/spark-exercise-pairrddfunctions-oneliners/ class=md-nav__link> One-liners using PairRDDFunctions </a> </li> <li class=md-nav__item> <a href=../../exercises/spark-exercise-take-multiple-jobs/ class=md-nav__link> Learning Jobs and Partitions Using take Action </a> </li> <li class=md-nav__item> <a href=../../exercises/spark-exercise-standalone-master-ha/ class=md-nav__link> Spark Standalone - Using ZooKeeper for High-Availability of Master </a> </li> <li class=md-nav__item> <a href=../../exercises/spark-hello-world-using-spark-shell/ class=md-nav__link> Spark's Hello World using Spark shell and Scala </a> </li> <li class=md-nav__item> <a href=../../exercises/spark-examples-wordcount-spark-shell/ class=md-nav__link> WordCount using Spark shell </a> </li> <li class=md-nav__item> <a href=../../exercises/spark-first-app/ class=md-nav__link> Your first complete Spark application (using Scala and sbt) </a> </li> <li class=md-nav__item> <a href=../../exercises/spark-sql-hive-orc-example/ class=md-nav__link> Using Spark SQL to update data in Hive using ORC files </a> </li> <li class=md-nav__item> <a href=../../exercises/spark-exercise-custom-scheduler-listener/ class=md-nav__link> Developing Custom SparkListener to monitor DAGScheduler in Scala </a> </li> <li class=md-nav__item> <a href=../../exercises/spark-exercise-custom-rdd/ class=md-nav__link> Developing Custom RDD </a> </li> <li class=md-nav__item> <a href=../../exercises/spark-exercise-dataframe-jdbc-postgresql/ class=md-nav__link> Working with Datasets from JDBC Data Sources (and PostgreSQL) </a> </li> <li class=md-nav__item> <a href=../../exercises/spark-exercise-failing-stage/ class=md-nav__link> Causing Stage to Fail </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-8 type=checkbox id=nav-8> <label class=md-nav__link for=nav-8> Web UI <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label="Web UI" data-md-level=1> <label class=md-nav__title for=nav-8> <span class="md-nav__icon md-icon"></span> Web UI </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../webui/ class=md-nav__link> Web UI </a> </li> <li class=md-nav__item> <a href=../../webui/configuration-properties/ class=md-nav__link> Configuration Properties </a> </li> <li class=md-nav__item> <a href=../../webui/WebUI/ class=md-nav__link> WebUI </a> </li> <li class=md-nav__item> <a href=../../webui/WebUIPage/ class=md-nav__link> WebUIPage </a> </li> <li class=md-nav__item> <a href=../../webui/WebUITab/ class=md-nav__link> WebUITab </a> </li> <li class=md-nav__item> <a href=../../webui/SparkUI/ class=md-nav__link> SparkUI </a> </li> <li class=md-nav__item> <a href=../../webui/SparkUITab/ class=md-nav__link> SparkUITab </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-8-8 type=checkbox id=nav-8-8> <label class=md-nav__link for=nav-8-8> Jobs Tab <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label="Jobs Tab" data-md-level=2> <label class=md-nav__title for=nav-8-8> <span class="md-nav__icon md-icon"></span> Jobs Tab </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../webui/jobs/ class=md-nav__link> Jobs </a> </li> <li class=md-nav__item> <a href=../../webui/spark-webui-JobsTab/ class=md-nav__link> JobsTab </a> </li> <li class=md-nav__item> <a href=../../webui/spark-webui-AllJobsPage/ class=md-nav__link> AllJobsPage </a> </li> <li class=md-nav__item> <a href=../../webui/spark-webui-JobPage/ class=md-nav__link> JobPage </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-8-9 type=checkbox id=nav-8-9> <label class=md-nav__link for=nav-8-9> Stages Tab <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label="Stages Tab" data-md-level=2> <label class=md-nav__title for=nav-8-9> <span class="md-nav__icon md-icon"></span> Stages Tab </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../webui/stages/ class=md-nav__link> Stages </a> </li> <li class=md-nav__item> <a href=../../webui/StagesTab/ class=md-nav__link> StagesTab </a> </li> <li class=md-nav__item> <a href=../../webui/AllStagesPage/ class=md-nav__link> AllStagesPage </a> </li> <li class=md-nav__item> <a href=../../webui/StagePage/ class=md-nav__link> StagePage </a> </li> <li class=md-nav__item> <a href=../../webui/PoolPage/ class=md-nav__link> PoolPage </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-8-10 type=checkbox id=nav-8-10> <label class=md-nav__link for=nav-8-10> Storage Tab <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label="Storage Tab" data-md-level=2> <label class=md-nav__title for=nav-8-10> <span class="md-nav__icon md-icon"></span> Storage Tab </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../webui/storage/ class=md-nav__link> Storage </a> </li> <li class=md-nav__item> <a href=../../webui/StorageTab/ class=md-nav__link> StorageTab </a> </li> <li class=md-nav__item> <a href=../../webui/StoragePage/ class=md-nav__link> StoragePage </a> </li> <li class=md-nav__item> <a href=../../webui/RDDPage/ class=md-nav__link> RDDPage </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-8-11 type=checkbox id=nav-8-11> <label class=md-nav__link for=nav-8-11> Environment Tab <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label="Environment Tab" data-md-level=2> <label class=md-nav__title for=nav-8-11> <span class="md-nav__icon md-icon"></span> Environment Tab </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../webui/environment/ class=md-nav__link> Environment </a> </li> <li class=md-nav__item> <a href=../../webui/EnvironmentTab/ class=md-nav__link> EnvironmentTab </a> </li> <li class=md-nav__item> <a href=../../webui/EnvironmentPage/ class=md-nav__link> EnvironmentPage </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-8-12 type=checkbox id=nav-8-12> <label class=md-nav__link for=nav-8-12> Executors <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label=Executors data-md-level=2> <label class=md-nav__title for=nav-8-12> <span class="md-nav__icon md-icon"></span> Executors </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../webui/executors/ class=md-nav__link> Executors </a> </li> <li class=md-nav__item> <a href=../../webui/ExecutorsTab/ class=md-nav__link> ExecutorsTab </a> </li> <li class=md-nav__item> <a href=../../webui/ExecutorsPage/ class=md-nav__link> ExecutorsPage </a> </li> <li class=md-nav__item> <a href=../../webui/ExecutorThreadDumpPage/ class=md-nav__link> ExecutorThreadDumpPage </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../../webui/BlockStatusListener/ class=md-nav__link> BlockStatusListener </a> </li> <li class=md-nav__item> <a href=../../webui/EnvironmentListener/ class=md-nav__link> EnvironmentListener </a> </li> <li class=md-nav__item> <a href=../../webui/ExecutorsListener/ class=md-nav__link> ExecutorsListener </a> </li> <li class=md-nav__item> <a href=../../webui/JobProgressListener/ class=md-nav__link> JobProgressListener </a> </li> <li class=md-nav__item> <a href=../../webui/StorageStatusListener/ class=md-nav__link> StorageStatusListener </a> </li> <li class=md-nav__item> <a href=../../webui/StorageListener/ class=md-nav__link> StorageListener </a> </li> <li class=md-nav__item> <a href=../../webui/RDDOperationGraphListener/ class=md-nav__link> RDDOperationGraphListener </a> </li> <li class=md-nav__item> <a href=../../webui/RDDStorageInfo/ class=md-nav__link> RDDStorageInfo </a> </li> <li class=md-nav__item> <a href=../../webui/LiveEntity/ class=md-nav__link> LiveEntity </a> </li> <li class=md-nav__item> <a href=../../webui/LiveRDD/ class=md-nav__link> LiveRDD </a> </li> <li class=md-nav__item> <a href=../../webui/UIUtils/ class=md-nav__link> UIUtils </a> </li> <li class=md-nav__item> <a href=../../webui/JettyUtils/ class=md-nav__link> JettyUtils </a> </li> </ul> </nav> </li> </ul> </nav> </div> </div> </div> <div class="md-sidebar md-sidebar--secondary" data-md-component=toc> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--secondary" aria-label="Table of contents"> </nav> </div> </div> </div> <div class=md-content> <article class="md-content__inner md-typeset"> <a href=https://github.com/japila-books/apache-spark-internals/edit/mkdocs-material/docs/scheduler/DAGScheduler.md title="Edit this page" class="md-content__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20.71 7.04c.39-.39.39-1.04 0-1.41l-2.34-2.34c-.37-.39-1.02-.39-1.41 0l-1.84 1.83 3.75 3.75M3 17.25V21h3.75L17.81 9.93l-3.75-3.75L3 17.25z"/></svg> </a> <p>= [[DAGScheduler]] DAGScheduler</p> <h1 id=note>[NOTE]<a class=headerlink href=#note title="Permanent link">&para;</a></h1> <h1 id=the-introduction-that-follows-was-highly-influenced-by-the-scaladoc-of-httpsgithubcomapachesparkblobmastercoresrcmainscalaorgapachesparkschedulerdagschedulerscalaorgapachesparkschedulerdagscheduler-as-dagscheduler-is-a-private-class-it-does-not-appear-in-the-official-api-documentation-you-are-strongly-encouraged-to-read-httpsgithubcomapachesparkblobmastercoresrcmainscalaorgapachesparkschedulerdagschedulerscalathe-sources-and-only-then-read-this-and-the-related-pages-afterwards>The introduction that follows was highly influenced by the scaladoc of <a href=https://github.com/apache/spark/blob/master/core/src/main/scala/org/apache/spark/scheduler/DAGScheduler.scala[org.apache.spark.scheduler.DAGScheduler>https://github.com/apache/spark/blob/master/core/src/main/scala/org/apache/spark/scheduler/DAGScheduler.scala[org.apache.spark.scheduler.DAGScheduler</a>]. As DAGScheduler is a private class it does not appear in the official API documentation. You are strongly encouraged to read <a href=https://github.com/apache/spark/blob/master/core/src/main/scala/org/apache/spark/scheduler/DAGScheduler.scala[the>https://github.com/apache/spark/blob/master/core/src/main/scala/org/apache/spark/scheduler/DAGScheduler.scala[the</a> sources] and only then read this and the related pages afterwards.<a class=headerlink href=#the-introduction-that-follows-was-highly-influenced-by-the-scaladoc-of-httpsgithubcomapachesparkblobmastercoresrcmainscalaorgapachesparkschedulerdagschedulerscalaorgapachesparkschedulerdagscheduler-as-dagscheduler-is-a-private-class-it-does-not-appear-in-the-official-api-documentation-you-are-strongly-encouraged-to-read-httpsgithubcomapachesparkblobmastercoresrcmainscalaorgapachesparkschedulerdagschedulerscalathe-sources-and-only-then-read-this-and-the-related-pages-afterwards title="Permanent link">&para;</a></h1> <p>== [[introduction]] Introduction</p> <p><em>DAGScheduler</em> is the scheduling layer of Apache Spark that implements <em>stage-oriented scheduling</em>.</p> <p>DAGScheduler transforms a <em>logical execution plan</em> (i.e. rdd/spark-rdd-lineage.md[RDD lineage] of dependencies built using rdd/spark-rdd-transformations.md[RDD transformations]) to a <em>physical execution plan</em> (using scheduler:Stage.md[stages]).</p> <p>.DAGScheduler Transforming RDD Lineage Into Stage DAG image::dagscheduler-rdd-lineage-stage-dag.png[align="center"]</p> <p>After an rdd/spark-rdd-actions.md[action] has been called, ROOT:SparkContext.md[SparkContext] hands over a logical plan to DAGScheduler that it in turn translates to a set of stages that are submitted as scheduler:TaskSet.md[TaskSets] for execution.</p> <p>.Executing action leads to new ResultStage and ActiveJob in DAGScheduler image::dagscheduler-rdd-partitions-job-resultstage.png[align="center"]</p> <p>The fundamental concepts of DAGScheduler are <em>jobs</em> and <em>stages</em> (refer to scheduler:spark-scheduler-ActiveJob.md[Jobs] and scheduler:Stage.md[Stages] respectively) that it tracks through &lt;<internal-registries, internal registries and counters>&gt;.</p> <p>DAGScheduler works solely on the driver and is created as part of ROOT:SparkContext.md#creating-instance[SparkContext's initialization] (right after scheduler:TaskScheduler.md[TaskScheduler] and scheduler:SchedulerBackend.md[SchedulerBackend] are ready).</p> <p>.DAGScheduler as created by SparkContext with other services image::dagscheduler-new-instance.png[align="center"]</p> <p>DAGScheduler does three things in Spark (thorough explanations follow):</p> <ul> <li>Computes an <em>execution DAG</em>, i.e. DAG of stages, for a job.</li> <li>Determines the &lt;<preferred-locations, preferred locations>&gt; to run each task on.</li> <li>Handles failures due to <em>shuffle output files</em> being lost.</li> </ul> <p>DAGScheduler computes <a href=https://en.wikipedia.org/wiki/Directed_acyclic_graph[a>https://en.wikipedia.org/wiki/Directed_acyclic_graph[a</a> directed acyclic graph (DAG)] of stages for each job, keeps track of which RDDs and stage outputs are materialized, and finds a minimal schedule to run jobs. It then submits stages to scheduler:TaskScheduler.md[TaskScheduler].</p> <p>.DAGScheduler.submitJob image::dagscheduler-submitjob.png[align="center"]</p> <p>In addition to coming up with the execution DAG, DAGScheduler also determines the preferred locations to run each task on, based on the current cache status, and passes the information to scheduler:TaskScheduler.md[TaskScheduler].</p> <p>DAGScheduler tracks which rdd/spark-rdd-caching.md[RDDs are cached (or persisted)] to avoid "recomputing" them, i.e. redoing the map side of a shuffle. DAGScheduler remembers what scheduler:ShuffleMapStage.md[ShuffleMapStage]s have already produced output files (that are stored in storage:BlockManager.md[BlockManager]s).</p> <p>DAGScheduler is only interested in cache location coordinates, i.e. host and executor id, per partition of a RDD.</p> <p>Furthermore, it handles failures due to shuffle output files being lost, in which case old stages may need to be resubmitted. Failures within a stage that are not caused by shuffle file loss are handled by the TaskScheduler itself, which will retry each task a small number of times before cancelling the whole stage.</p> <p>DAGScheduler uses an <em>event queue architecture</em> in which a thread can post <code>DAGSchedulerEvent</code> events, e.g. a new job or stage being submitted, that DAGScheduler reads and executes sequentially. See the section &lt;<event-loop, internal event loop - dag-scheduler-event-loop>&gt;.</p> <p>DAGScheduler runs stages in topological order.</p> <p>DAGScheduler uses ROOT:SparkContext.md[SparkContext], scheduler:TaskScheduler.md[TaskScheduler], scheduler:LiveListenerBus.md[], scheduler:MapOutputTracker.md[MapOutputTracker] and storage:BlockManager.md[BlockManager] for its services. However, at the very minimum, DAGScheduler takes a <code>SparkContext</code> only (and requests <code>SparkContext</code> for the other services).</p> <p>When DAGScheduler schedules a job as a result of rdd/index.md#actions[executing an action on a RDD] or ROOT:SparkContext.md#runJob[calling SparkContext.runJob() method directly], it spawns parallel tasks to compute (partial) results per partition.</p> <p>== [[creating-instance]][[initialization]] Creating Instance</p> <p>DAGScheduler takes the following to be created:</p> <ul> <li>[[sc]] ROOT:SparkContext.md[]</li> <li>&lt;<taskscheduler, taskscheduler>&gt;</li> <li>[[listenerBus]] scheduler:LiveListenerBus.md[]</li> <li>[[mapOutputTracker]] scheduler:MapOutputTrackerMaster.md[MapOutputTrackerMaster]</li> <li>[[blockManagerMaster]] storage:BlockManagerMaster.md[BlockManagerMaster]</li> <li>[[env]] core:SparkEnv.md[]</li> <li>[[clock]] Clock (default: SystemClock)</li> </ul> <p>While being created, DAGScheduler scheduler:TaskScheduler.md#setDAGScheduler[associates itself] with the &lt;<taskscheduler, taskscheduler>&gt; and starts &lt;<eventprocessloop, dagscheduler event bus>&gt;.</p> <p>== [[event-loop]][[eventProcessLoop]] DAGScheduler Event Bus</p> <p>DAGScheduler uses an scheduler:DAGSchedulerEventProcessLoop.md[event bus] to process scheduling-related events on a separate thread (one by one and asynchronously).</p> <p>DAGScheduler starts the event bus when created and stops it when requested to &lt;<stop, stop>&gt;.</p> <p>DAGScheduler defines &lt;<event-posting-methods, event-posting methods>&gt; that allow posting DAGSchedulerEvent events to the event bus.</p> <p>[[event-posting-methods]] .DAGScheduler Event Posting Methods [cols="20m,20m,60",options="header",width="100%"] |=== | Method | Event Posted | Trigger</p> <p>| [[cancelAllJobs]] cancelAllJobs | scheduler:DAGSchedulerEvent.md#AllJobsCancelled[AllJobsCancelled] | SparkContext is requested to ROOT:SparkContext.md#cancelAllJobs[cancel all running or scheduled Spark jobs]</p> <p>| [[cancelJob]] cancelJob | scheduler:DAGSchedulerEvent.md#JobCancelled[JobCancelled] | ROOT:SparkContext.md#cancelJob[SparkContext] or scheduler:spark-scheduler-JobWaiter.md[JobWaiter] are requested to cancel a Spark job</p> <p>| [[cancelJobGroup]] cancelJobGroup | scheduler:DAGSchedulerEvent.md#JobGroupCancelled[JobGroupCancelled] | SparkContext is requested to ROOT:SparkContext.md#cancelJobGroup[cancel a job group]</p> <p>| [[cancelStage]] cancelStage | scheduler:DAGSchedulerEvent.md#StageCancelled[StageCancelled] | SparkContext is requested to ROOT:SparkContext.md#cancelStage[cancel a stage]</p> <p>| [[executorAdded]] executorAdded | scheduler:DAGSchedulerEvent.md#ExecutorAdded[ExecutorAdded] | TaskSchedulerImpl is requested to scheduler:TaskSchedulerImpl.md#resourceOffers[handle resource offers] (and a new executor is found in the resource offers)</p> <p>| [[executorLost]] executorLost | scheduler:DAGSchedulerEvent.md#ExecutorLost[ExecutorLost] | TaskSchedulerImpl is requested to scheduler:TaskSchedulerImpl.md#statusUpdate[handle a task status update] (and a task gets lost which is used to indicate that the executor got broken and hence should be considered lost) or scheduler:TaskSchedulerImpl.md#executorLost[executorLost]</p> <p>| [[runApproximateJob]] runApproximateJob | scheduler:DAGSchedulerEvent.md#JobSubmitted[JobSubmitted] | SparkContext is requested to ROOT:SparkContext.md#runApproximateJob[run an approximate job]</p> <p>| [[speculativeTaskSubmitted]] speculativeTaskSubmitted | scheduler:DAGSchedulerEvent.md#SpeculativeTaskSubmitted[SpeculativeTaskSubmitted] |</p> <p>| [[submitJob]] submitJob | scheduler:DAGSchedulerEvent.md#JobSubmitted[JobSubmitted] a|</p> <ul> <li> <p>SparkContext is requested to ROOT:SparkContext.md#submitJob[submits a job]</p> </li> <li> <p>DAGScheduler is requested to &lt;<runjob, run a job>&gt;</p> </li> </ul> <p>| [[submitMapStage]] submitMapStage | scheduler:DAGSchedulerEvent.md#MapStageSubmitted[MapStageSubmitted] | SparkContext is requested to ROOT:SparkContext.md#submitMapStage[submit a MapStage for execution].</p> <p>| [[taskEnded]] taskEnded | scheduler:DAGSchedulerEvent.md#CompletionEvent[CompletionEvent] | TaskSetManager is requested to scheduler:TaskSetManager.md#handleSuccessfulTask[handleSuccessfulTask], scheduler:TaskSetManager.md#handleFailedTask[handleFailedTask], and scheduler:TaskSetManager.md#executorLost[executorLost]</p> <p>| [[taskGettingResult]] taskGettingResult | scheduler:DAGSchedulerEvent.md#GettingResultEvent[GettingResultEvent] | TaskSetManager is requested to scheduler:TaskSetManager.md#handleTaskGettingResult[handle a task fetching result]</p> <p>| [[taskSetFailed]] taskSetFailed | scheduler:DAGSchedulerEvent.md#TaskSetFailed[TaskSetFailed] | TaskSetManager is requested to scheduler:TaskSetManager.md#abort[abort]</p> <p>| [[taskStarted]] taskStarted | scheduler:DAGSchedulerEvent.md#BeginEvent[BeginEvent] | TaskSetManager is requested to scheduler:TaskSetManager.md#resourceOffer[start a task]</p> <p>| [[workerRemoved]] workerRemoved | scheduler:DAGSchedulerEvent.md#WorkerRemoved[WorkerRemoved] | TaskSchedulerImpl is requested to scheduler:TaskSchedulerImpl.md#workerRemoved[handle a removed worker event]</p> <p>|===</p> <p>== [[taskScheduler]] DAGScheduler and TaskScheduler</p> <p>DAGScheduler is given a scheduler:TaskScheduler.md[TaskScheduler] when &lt;<creating-instance, created>&gt;.</p> <p>DAGScheduler uses the TaskScheduler for the following:</p> <ul> <li> <p>&lt;<submitmissingtasks, submitting missing tasks of a stage>&gt;</p> </li> <li> <p>&lt;<handletaskcompletion, handling task completion (completionevent)>&gt;</p> </li> <li> <p>&lt;<killtaskattempt, killing a task>&gt;</p> </li> <li> <p>&lt;<failjobandindependentstages, failing a job and all other independent single-job stages>&gt;</p> </li> <li> <p>&lt;<stop, stopping itself>&gt;</p> </li> </ul> <p>== [[runJob]] Running Job</p> <h2 id=source-scala>[source, scala]<a class=headerlink href=#source-scala title="Permanent link">&para;</a></h2> <p>runJob<a href="rdd/ RDD[T],
  func: (TaskContext, Iterator[T]) => U,
  partitions: Seq[Int],
  callSite: CallSite,
  resultHandler: (Int, U) => Unit,
  properties: Properties">T, U</a>: Unit</p> <hr> <p>runJob submits an action job to the DAGScheduler and waits for a result.</p> <p>Internally, runJob executes &lt;<submitjob, submitjob>&gt; and then waits until a result comes using scheduler:spark-scheduler-JobWaiter.md[JobWaiter].</p> <p>When the job succeeds, you should see the following INFO message in the logs:</p> <div class=highlight><pre><span></span><code>Job [jobId] finished: [callSite], took [time] s
</code></pre></div> <p>When the job fails, you should see the following INFO message in the logs and the exception (that led to the failure) is thrown.</p> <div class=highlight><pre><span></span><code>Job [jobId] failed: [callSite], took [time] s
</code></pre></div> <p>runJob is used when SparkContext is requested to ROOT:SparkContext.md#runJob[run a job].</p> <p>== [[cacheLocs]][[clearCacheLocs]] Partition Placement Preferences</p> <p>DAGScheduler keeps track of block locations per RDD and partition.</p> <p>DAGScheduler uses scheduler:TaskLocation.md[TaskLocation] that includes a host name and an executor id on that host (as <code>ExecutorCacheTaskLocation</code>).</p> <p>The keys are RDDs (their ids) and the values are arrays indexed by partition numbers.</p> <p>Each entry is a set of block locations where a RDD partition is cached, i.e. the storage:BlockManager.md[BlockManager]s of the blocks.</p> <p>Initialized empty when &lt;<creating-instance, dagscheduler is created>&gt;.</p> <p>Used when DAGScheduler is requested for the &lt;<getcachelocs, locations of the cache blocks of a rdd>&gt; or &lt;<clearcachelocs, clear them>&gt;.</p> <p>== [[activeJobs]] ActiveJobs</p> <p>DAGScheduler tracks scheduler:spark-scheduler-ActiveJob.md[ActiveJobs]:</p> <ul> <li> <p>Adds a new ActiveJob when requested to handle &lt;<handlejobsubmitted, jobsubmitted>&gt; or &lt;<handlemapstagesubmitted, mapstagesubmitted>&gt; events</p> </li> <li> <p>Removes an ActiveJob when requested to &lt;<cleanupstateforjobandindependentstages, clean up after an activejob and independent stages>&gt;.</p> </li> <li> <p>Removes all ActiveJobs when requested to &lt;<docancelalljobs, docancelalljobs>&gt;.</p> </li> </ul> <p>DAGScheduler uses ActiveJobs registry when requested to handle &lt;<handlejobgroupcancelled, jobgroupcancelled>&gt; or &lt;<handletaskcompletion, taskcompletion>&gt; events, to &lt;<cleanupafterschedulerstop, cleanupafterschedulerstop>&gt; and to &lt;<abortstage, abort a stage>&gt;.</p> <p>The number of ActiveJobs is available using metrics:spark-scheduler-DAGSchedulerSource.md#job.activeJobs[job.activeJobs] performance metric.</p> <p>== [[createResultStage]] Creating ResultStage for RDD</p> <h2 id=source-scala_1>[source, scala]<a class=headerlink href=#source-scala_1 title="Permanent link">&para;</a></h2> <p>createResultStage( rdd/ RDD[<em>], func: (TaskContext, Iterator[</em>]) =&gt; _, partitions: Array[Int], jobId: Int, callSite: CallSite): ResultStage</p> <hr> <p>createResultStage...FIXME</p> <p>createResultStage is used when DAGScheduler is requested to &lt;<handlejobsubmitted, handle a jobsubmitted event>&gt;.</p> <p>== [[createShuffleMapStage]] Creating ShuffleMapStage for ShuffleDependency</p> <h2 id=source-scala_2>[source, scala]<a class=headerlink href=#source-scala_2 title="Permanent link">&para;</a></h2> <p>createShuffleMapStage( shuffleDep: ShuffleDependency[_, _, _], jobId: Int): ShuffleMapStage</p> <hr> <p>createShuffleMapStage creates a scheduler:ShuffleMapStage.md[ShuffleMapStage] for the given <a href=../../rdd/ShuffleDependency/ >ShuffleDependency</a> as follows:</p> <ul> <li> <p>Stage ID is generated based on &lt;<nextstageid, nextstageid>&gt; internal counter</p> </li> <li> <p>RDD is taken from the given <a href=../../rdd/ShuffleDependency/#rdd>ShuffleDependency</a></p> </li> <li> <p>Number of tasks is the number of <a href=../../rdd/RDD/#partitions>partitions</a> of the RDD</p> </li> <li> <p>&lt;<getorcreateparentstages, parent rdds>&gt;</p> </li> <li> <p>&lt;<mapoutputtracker, mapoutputtrackermaster>&gt;</p> </li> </ul> <p>createShuffleMapStage registers the ShuffleMapStage in the &lt;<stageidtostage, stageidtostage>&gt; and &lt;<shuffleidtomapstage, shuffleidtomapstage>&gt; internal registries.</p> <p>createShuffleMapStage &lt;<updatejobidstageidmaps, updatejobidstageidmaps>&gt;.</p> <p>createShuffleMapStage requests the &lt;<mapoutputtracker, mapoutputtrackermaster>&gt; to scheduler:MapOutputTrackerMaster.md#containsShuffle[check whether it contains the shuffle ID or not].</p> <p>If not, createShuffleMapStage prints out the following INFO message to the logs and requests the &lt;<mapoutputtracker, mapoutputtrackermaster>&gt; to scheduler:MapOutputTrackerMaster.md#registerShuffle[register the shuffle].</p> <h2 id=sourceplaintext>[source,plaintext]<a class=headerlink href=#sourceplaintext title="Permanent link">&para;</a></h2> <h2 id=registering-rdd-id-creationsite-as-input-to-shuffle-shuffleid>Registering RDD [id] ([creationSite]) as input to shuffle [shuffleId]<a class=headerlink href=#registering-rdd-id-creationsite-as-input-to-shuffle-shuffleid title="Permanent link">&para;</a></h2> <p>.DAGScheduler Asks <code>MapOutputTrackerMaster</code> Whether Shuffle Map Output Is Already Tracked image::DAGScheduler-MapOutputTrackerMaster-containsShuffle.png[align="center"]</p> <p>createShuffleMapStage is used when DAGScheduler is requested to &lt;<getorcreateshufflemapstage, find or create a shufflemapstage for a given shuffledependency>&gt;.</p> <p>== [[cleanupStateForJobAndIndependentStages]] Cleaning Up After Job and Independent Stages</p> <h2 id=source-scala_3>[source, scala]<a class=headerlink href=#source-scala_3 title="Permanent link">&para;</a></h2> <p>cleanupStateForJobAndIndependentStages( job: ActiveJob): Unit</p> <hr> <p>cleanupStateForJobAndIndependentStages cleans up the state for <code>job</code> and any stages that are <em>not</em> part of any other job.</p> <p>cleanupStateForJobAndIndependentStages looks the <code>job</code> up in the internal &lt;<jobidtostageids, jobidtostageids>&gt; registry.</p> <p>If no stages are found, the following ERROR is printed out to the logs:</p> <div class=highlight><pre><span></span><code>No stages registered for job [jobId]
</code></pre></div> <p>Oterwise, cleanupStateForJobAndIndependentStages uses &lt;<stageidtostage, stageidtostage>&gt; registry to find the stages (the real objects not ids!).</p> <p>For each stage, cleanupStateForJobAndIndependentStages reads the jobs the stage belongs to.</p> <p>If the <code>job</code> does not belong to the jobs of the stage, the following ERROR is printed out to the logs:</p> <div class=highlight><pre><span></span><code>Job [jobId] not registered for stage [stageId] even though that stage was registered for the job
</code></pre></div> <p>If the <code>job</code> was the only job for the stage, the stage (and the stage id) gets cleaned up from the registries, i.e. &lt;<runningstages, runningstages>&gt;, &lt;<shuffleidtomapstage, shuffleidtomapstage>&gt;, &lt;<waitingstages, waitingstages>&gt;, &lt;<failedstages, failedstages>&gt; and &lt;<stageidtostage, stageidtostage>&gt;.</p> <p>While removing from &lt;<runningstages, runningstages>&gt;, you should see the following DEBUG message in the logs:</p> <div class=highlight><pre><span></span><code>Removing running stage [stageId]
</code></pre></div> <p>While removing from &lt;<waitingstages, waitingstages>&gt;, you should see the following DEBUG message in the logs:</p> <div class=highlight><pre><span></span><code>Removing stage [stageId] from waiting set.
</code></pre></div> <p>While removing from &lt;<failedstages, failedstages>&gt;, you should see the following DEBUG message in the logs:</p> <div class=highlight><pre><span></span><code>Removing stage [stageId] from failed set.
</code></pre></div> <p>After all cleaning (using &lt;<stageidtostage, stageidtostage>&gt; as the source registry), if the stage belonged to the one and only <code>job</code>, you should see the following DEBUG message in the logs:</p> <div class=highlight><pre><span></span><code>After removal of stage [stageId], remaining stages = [stageIdToStage.size]
</code></pre></div> <p>The <code>job</code> is removed from &lt;<jobidtostageids, jobidtostageids>&gt;, &lt;<jobidtoactivejob, jobidtoactivejob>&gt;, &lt;<activejobs, activejobs>&gt; registries.</p> <p>The final stage of the <code>job</code> is removed, i.e. scheduler:ResultStage.md#removeActiveJob[ResultStage] or scheduler:ShuffleMapStage.md#removeActiveJob[ShuffleMapStage].</p> <p>cleanupStateForJobAndIndependentStages is used in scheduler:DAGSchedulerEventProcessLoop.md#handleTaskCompletion-Success-ResultTask[handleTaskCompletion when a <code>ResultTask</code> has completed successfully], &lt;<failjobandindependentstages, failjobandindependentstages>&gt; and &lt;<markmapstagejobasfinished, markmapstagejobasfinished>&gt;.</p> <p>== [[markMapStageJobAsFinished]] Marking ShuffleMapStage Job Finished</p> <h2 id=source-scala_4>[source, scala]<a class=headerlink href=#source-scala_4 title="Permanent link">&para;</a></h2> <p>markMapStageJobAsFinished( job: ActiveJob, stats: MapOutputStatistics): Unit</p> <hr> <p>markMapStageJobAsFinished marks the active <code>job</code> finished and notifies Spark listeners.</p> <p>Internally, markMapStageJobAsFinished marks the zeroth partition finished and increases the number of tasks finished in <code>job</code>.</p> <p>The scheduler:spark-scheduler-JobListener.md#taskSucceeded[<code>job</code> listener is notified about the 0<sup>th</sup> task succeeded].</p> <p>The &lt;<cleanupstateforjobandindependentstages, state of the &lt;code>job</code> and independent stages are cleaned up>&gt;.</p> <p>Ultimately, ROOT:SparkListener.md#SparkListenerJobEnd[SparkListenerJobEnd] is posted to scheduler:LiveListenerBus.md[] (as &lt;<listenerbus, listenerbus>&gt;) for the <code>job</code>, the current time (in millis) and <code>JobSucceeded</code> job result.</p> <p>markMapStageJobAsFinished is used in scheduler:DAGSchedulerEventProcessLoop.md#handleMapStageSubmitted[handleMapStageSubmitted] and scheduler:DAGSchedulerEventProcessLoop.md#handleTaskCompletion[handleTaskCompletion].</p> <p>== [[getOrCreateParentStages]] Finding Or Creating Missing Direct Parent ShuffleMapStages (For ShuffleDependencies) of RDD</p> <h2 id=source-scala_5>[source, scala]<a class=headerlink href=#source-scala_5 title="Permanent link">&para;</a></h2> <p>getOrCreateParentStages( rdd/ RDD[_], firstJobId: Int): List[Stage]</p> <hr> <p>getOrCreateParentStages &lt;<getshuffledependencies, finds all direct parent &lt;code>ShuffleDependencies</code>>&gt; of the input <code>rdd</code> and then &lt;<getorcreateshufflemapstage, finds &lt;code>ShuffleMapStage</code> stages>&gt; for each <a href=../../rdd/ShuffleDependency/ >ShuffleDependency</a>.</p> <p>getOrCreateParentStages is used when DAGScheduler is requested to create a &lt;<createshufflemapstage, shufflemapstage>&gt; or a &lt;<createresultstage, resultstage>&gt;.</p> <p>== [[markStageAsFinished]] Marking Stage Finished</p> <h2 id=source-scala_6>[source, scala]<a class=headerlink href=#source-scala_6 title="Permanent link">&para;</a></h2> <p>markStageAsFinished( stage: Stage, errorMessage: Option[String] = None, willRetry: Boolean = false): Unit</p> <hr> <p>markStageAsFinished...FIXME</p> <p>markStageAsFinished is used when...FIXME</p> <p>== [[getOrCreateShuffleMapStage]] Finding or Creating ShuffleMapStage for ShuffleDependency</p> <h2 id=source-scala_7>[source, scala]<a class=headerlink href=#source-scala_7 title="Permanent link">&para;</a></h2> <p>getOrCreateShuffleMapStage( shuffleDep: ShuffleDependency[_, _, _], firstJobId: Int): ShuffleMapStage</p> <hr> <p>getOrCreateShuffleMapStage finds the scheduler:ShuffleMapStage.md[ShuffleMapStage] in the &lt;<shuffleidtomapstage, shuffleidtomapstage>&gt; internal registry and returns it if available.</p> <p>If not found, getOrCreateShuffleMapStage &lt;<getmissingancestorshuffledependencies, finds all the missing ancestor shuffle dependencies>&gt; and &lt;<createshufflemapstage, creates the shufflemapstage stages>&gt; (including one for the input ShuffleDependency).</p> <p>getOrCreateShuffleMapStage is used when DAGScheduler is requested to &lt;<getorcreateparentstages, find or create missing direct parent shufflemapstages of an rdd>&gt;, &lt;<getmissingparentstages, find missing parent shufflemapstages for a stage>&gt;, &lt;<handlemapstagesubmitted, handle a mapstagesubmitted event>&gt;, and &lt;<stagedependson, check out stage dependency on a stage>&gt;.</p> <p>== [[getMissingAncestorShuffleDependencies]] Finding Missing ShuffleDependencies For RDD</p> <h2 id=source-scala_8>[source, scala]<a class=headerlink href=#source-scala_8 title="Permanent link">&para;</a></h2> <p>getMissingAncestorShuffleDependencies( rdd/ RDD[<em>]): Stack[ShuffleDependency[</em>, _, _]]</p> <hr> <p>getMissingAncestorShuffleDependencies finds all missing <a href=../../rdd/ShuffleDependency/ >shuffle dependencies</a> for the given <a href=../../rdd/ >RDD</a> traversing its rdd/spark-rdd-lineage.md[RDD lineage].</p> <p>NOTE: A <em>missing shuffle dependency</em> of a RDD is a dependency not registered in &lt;<shuffleidtomapstage, &lt;code>shuffleIdToMapStage</code> internal registry>&gt;.</p> <p>Internally, getMissingAncestorShuffleDependencies &lt;<getshuffledependencies, finds direct parent shuffle dependencies>&gt;of the input RDD and collects the ones that are not registered in &lt;<shuffleidtomapstage, &lt;code>shuffleIdToMapStage</code> internal registry>&gt;. It repeats the process for the RDDs of the parent shuffle dependencies.</p> <p>getMissingAncestorShuffleDependencies is used when DAGScheduler is requested to &lt;<getorcreateshufflemapstage, find all shufflemapstage stages for a shuffledependency>&gt;.</p> <p>== [[getShuffleDependencies]] Finding Direct Parent Shuffle Dependencies of RDD</p> <h2 id=source-scala_9>[source, scala]<a class=headerlink href=#source-scala_9 title="Permanent link">&para;</a></h2> <p>getShuffleDependencies( rdd/ RDD[<em>]): HashSet[ShuffleDependency[</em>, _, _]]</p> <hr> <p>getShuffleDependencies finds direct parent <a href=../../rdd/ShuffleDependency/ >shuffle dependencies</a> for the given <a href=../../rdd/ >RDD</a>.</p> <p><img alt="getShuffleDependencies Finds Direct Parent ShuffleDependencies (shuffle1 and shuffle2)" src=../../images/scheduler/spark-DAGScheduler-getShuffleDependencies.png></p> <p>Internally, getShuffleDependencies takes the direct rdd/index.md#dependencies[shuffle dependencies of the input RDD] and direct shuffle dependencies of all the parent non-<code>ShuffleDependencies</code> in the <a href=../../rdd/spark-rdd-lineage/ >dependency chain</a> (aka <em>RDD lineage</em>).</p> <p>getShuffleDependencies is used when DAGScheduler is requested to &lt;<getorcreateparentstages, find or create missing direct parent shufflemapstages>&gt; (for ShuffleDependencies of a RDD) and &lt;<getmissingancestorshuffledependencies, find all missing shuffle dependencies for a given rdd>&gt;.</p> <p>== [[failJobAndIndependentStages]] Failing Job and Independent Single-Job Stages</p> <h2 id=source-scala_10>[source, scala]<a class=headerlink href=#source-scala_10 title="Permanent link">&para;</a></h2> <p>failJobAndIndependentStages( job: ActiveJob, failureReason: String, exception: Option[Throwable] = None): Unit</p> <hr> <p>failJobAndIndependentStages fails the input <code>job</code> and all the stages that are only used by the job.</p> <p>Internally, failJobAndIndependentStages uses &lt;<jobidtostageids, &lt;code>jobIdToStageIds</code> internal registry>&gt; to look up the stages registered for the job.</p> <p>If no stages could be found, you should see the following ERROR message in the logs:</p> <div class=highlight><pre><span></span><code>No stages registered for job [id]
</code></pre></div> <p>Otherwise, for every stage, failJobAndIndependentStages finds the job ids the stage belongs to.</p> <p>If no stages could be found or the job is not referenced by the stages, you should see the following ERROR message in the logs:</p> <div class=highlight><pre><span></span><code>Job [id] not registered for stage [id] even though that stage was registered for the job
</code></pre></div> <p>Only when there is exactly one job registered for the stage and the stage is in RUNNING state (in <code>runningStages</code> internal registry), scheduler:TaskScheduler.md#contract[<code>TaskScheduler</code> is requested to cancel the stage's tasks] and &lt;<markstageasfinished, marks the stage finished>&gt;.</p> <p>NOTE: failJobAndIndependentStages uses &lt;<jobidtostageids, jobidtostageids>&gt;, &lt;<stageidtostage, stageidtostage>&gt;, and &lt;<runningstages, runningstages>&gt; internal registries.</p> <p>failJobAndIndependentStages is used when...FIXME</p> <p>== [[abortStage]] Aborting Stage</p> <h2 id=source-scala_11>[source, scala]<a class=headerlink href=#source-scala_11 title="Permanent link">&para;</a></h2> <p>abortStage( failedStage: Stage, reason: String, exception: Option[Throwable]): Unit</p> <hr> <p>abortStage is an internal method that finds all the active jobs that depend on the <code>failedStage</code> stage and fails them.</p> <p>Internally, abortStage looks the <code>failedStage</code> stage up in the internal &lt;<stageidtostage, stageidtostage>&gt; registry and exits if there the stage was not registered earlier.</p> <p>If it was, abortStage finds all the active jobs (in the internal &lt;<activejobs, activejobs>&gt; registry) with the &lt;<stagedependson, final stage depending on the &lt;code>failedStage</code> stage>&gt;.</p> <p>At this time, the <code>completionTime</code> property (of the failed stage's scheduler:spark-scheduler-StageInfo.md[StageInfo]) is assigned to the current time (millis).</p> <p>All the active jobs that depend on the failed stage (as calculated above) and the stages that do not belong to other jobs (aka <em>independent stages</em>) are &lt;<failjobandindependentstages, failed>&gt; (with the failure reason being "Job aborted due to stage failure: [reason]" and the input <code>exception</code>).</p> <p>If there are no jobs depending on the failed stage, you should see the following INFO message in the logs:</p> <h2 id=sourceplaintext_1>[source,plaintext]<a class=headerlink href=#sourceplaintext_1 title="Permanent link">&para;</a></h2> <h2 id=ignoring-failure-of-failedstage-because-all-jobs-depending-on-it-are-done>Ignoring failure of [failedStage] because all jobs depending on it are done<a class=headerlink href=#ignoring-failure-of-failedstage-because-all-jobs-depending-on-it-are-done title="Permanent link">&para;</a></h2> <p>abortStage is used when DAGScheduler is requested to &lt;<handletasksetfailed, handle a tasksetfailed event>&gt;, &lt;<submitstage, submit a stage>&gt;, &lt;<submitmissingtasks, submit missing tasks of a stage>&gt;, &lt;<handletaskcompletion, handle a taskcompletion event>&gt;.</p> <p>== [[stageDependsOn]] Checking Out Stage Dependency on Given Stage</p> <h2 id=source-scala_12>[source, scala]<a class=headerlink href=#source-scala_12 title="Permanent link">&para;</a></h2> <p>stageDependsOn( stage: Stage, target: Stage): Boolean</p> <hr> <p>stageDependsOn compares two stages and returns whether the <code>stage</code> depends on <code>target</code> stage (i.e. <code>true</code>) or not (i.e. <code>false</code>).</p> <p>NOTE: A stage <code>A</code> depends on stage <code>B</code> if <code>B</code> is among the ancestors of <code>A</code>.</p> <p>Internally, stageDependsOn walks through the graph of RDDs of the input <code>stage</code>. For every RDD in the RDD's dependencies (using <code>RDD.dependencies</code>) stageDependsOn adds the RDD of a <a href=../../rdd/NarrowDependency/ >NarrowDependency</a> to a stack of RDDs to visit while for a <a href=../../rdd/ShuffleDependency/ >ShuffleDependency</a> it &lt;<getorcreateshufflemapstage, finds &lt;code>ShuffleMapStage</code> stages for a <code>ShuffleDependency</code>>&gt; for the dependency and the <code>stage</code>'s first job id that it later adds to a stack of RDDs to visit if the map stage is ready, i.e. all the partitions have shuffle outputs.</p> <p>After all the RDDs of the input <code>stage</code> are visited, stageDependsOn checks if the <code>target</code>'s RDD is among the RDDs of the <code>stage</code>, i.e. whether the <code>stage</code> depends on <code>target</code> stage.</p> <p>stageDependsOn is used when DAGScheduler is requested to &lt;<abortstage, abort a stage>&gt;.</p> <p>== [[submitWaitingChildStages]] Submitting Waiting Child Stages for Execution</p> <h2 id=source-scala_13>[source, scala]<a class=headerlink href=#source-scala_13 title="Permanent link">&para;</a></h2> <p>submitWaitingChildStages( parent: Stage): Unit</p> <hr> <p>submitWaitingChildStages submits for execution all waiting stages for which the input <code>parent</code> scheduler:Stage.md[Stage] is the direct parent.</p> <p>NOTE: <em>Waiting stages</em> are the stages registered in &lt;<waitingstages, &lt;code>waitingStages</code> internal registry>&gt;.</p> <p>When executed, you should see the following <code>TRACE</code> messages in the logs:</p> <div class=highlight><pre><span></span><code>Checking if any dependencies of [parent] are now runnable
running: [runningStages]
waiting: [waitingStages]
failed: [failedStages]
</code></pre></div> <p>submitWaitingChildStages finds child stages of the input <code>parent</code> stage, removes them from <code>waitingStages</code> internal registry, and &lt;<submitstage, submits>&gt; one by one sorted by their job ids.</p> <p>submitWaitingChildStages is used when DAGScheduler is requested to &lt;<submitmissingtasks, submits missing tasks for a stage>&gt; and &lt;<handletaskcompletion, handles a successful shufflemaptask completion>&gt;.</p> <p>== [[submitStage]] Submitting Stage (with Missing Parents) for Execution</p> <h2 id=source-scala_14>[source, scala]<a class=headerlink href=#source-scala_14 title="Permanent link">&para;</a></h2> <p>submitStage( stage: Stage): Unit</p> <hr> <p>submitStage submits the input <code>stage</code> or its missing parents (if there any stages not computed yet before the input <code>stage</code> could).</p> <p>NOTE: submitStage is also used to scheduler:DAGSchedulerEventProcessLoop.md#resubmitFailedStages[resubmit failed stages].</p> <p>submitStage recursively submits any missing parents of the <code>stage</code>.</p> <p>Internally, submitStage first finds the earliest-created job id that needs the <code>stage</code>.</p> <p>NOTE: A stage itself tracks the jobs (their ids) it belongs to (using the internal <code>jobIds</code> registry).</p> <p>The following steps depend on whether there is a job or not.</p> <p>If there are no jobs that require the <code>stage</code>, submitStage &lt;<abortstage, aborts it>&gt; with the reason:</p> <div class=highlight><pre><span></span><code>No active job for stage [id]
</code></pre></div> <p>If however there is a job for the <code>stage</code>, you should see the following DEBUG message in the logs:</p> <div class=highlight><pre><span></span><code>submitStage([stage])
</code></pre></div> <p>submitStage checks the status of the <code>stage</code> and continues when it was not recorded in &lt;<waitingstages, waiting>&gt;, &lt;<runningstages, running>&gt; or &lt;<failedstages, failed>&gt; internal registries. It simply exits otherwise.</p> <p>With the <code>stage</code> ready for submission, submitStage calculates the &lt;<getmissingparentstages, list of missing parent stages of the &lt;code>stage</code>>&gt; (sorted by their job ids). You should see the following DEBUG message in the logs:</p> <div class=highlight><pre><span></span><code>missing: [missing]
</code></pre></div> <p>When the <code>stage</code> has no parent stages missing, you should see the following INFO message in the logs:</p> <div class=highlight><pre><span></span><code>Submitting [stage] ([stage.rdd]), which has no missing parents
</code></pre></div> <p>submitStage &lt;<submitmissingtasks, submits the &lt;code>stage</code>>&gt; (with the earliest-created job id) and finishes.</p> <p>If however there are missing parent stages for the <code>stage</code>, submitStage &lt;<submitstage, submits all the parent stages>&gt;, and the <code>stage</code> is recorded in the internal &lt;<waitingstages, waitingstages>&gt; registry.</p> <p>submitStage is used recursively for missing parents of the given stage and when DAGScheduler is requested for the following:</p> <ul> <li> <p>&lt;<resubmitfailedstages, resubmitfailedstages>&gt; (ResubmitFailedStages event)</p> </li> <li> <p>&lt;<submitwaitingchildstages, submitwaitingchildstages>&gt; (CompletionEvent event)</p> </li> <li> <p>Handle &lt;<handlejobsubmitted, jobsubmitted>&gt;, &lt;<handlemapstagesubmitted, mapstagesubmitted>&gt; and &lt;<handletaskcompletion, taskcompletion>&gt; events</p> </li> </ul> <p>== [[stage-attempts]] Stage Attempts</p> <p>A single stage can be re-executed in multiple <em>attempts</em> due to fault recovery. The number of attempts is configured (FIXME).</p> <p>If <code>TaskScheduler</code> reports that a task failed because a map output file from a previous stage was lost, the DAGScheduler resubmits the lost stage. This is detected through a scheduler:DAGSchedulerEventProcessLoop.md#handleTaskCompletion-FetchFailed[<code>CompletionEvent</code> with <code>FetchFailed</code>], or an &lt;<executorlost, executorlost>&gt; event. DAGScheduler will wait a small amount of time to see whether other nodes or tasks fail, then resubmit <code>TaskSets</code> for any lost stage(s) that compute the missing tasks.</p> <p>Please note that tasks from the old attempts of a stage could still be running.</p> <p>A stage object tracks multiple scheduler:spark-scheduler-StageInfo.md[StageInfo] objects to pass to Spark listeners or the web UI.</p> <p>The latest <code>StageInfo</code> for the most recent attempt for a stage is accessible through <code>latestInfo</code>.</p> <p>== [[preferred-locations]] Preferred Locations</p> <p>DAGScheduler computes where to run each task in a stage based on the rdd/index.md#getPreferredLocations[preferred locations of its underlying RDDs], or &lt;<getcachelocs, the location of cached or shuffle data>&gt;.</p> <p>== [[adaptive-query-planning]] Adaptive Query Planning / Adaptive Scheduling</p> <p>See <a href=https://issues.apache.org/jira/browse/SPARK-9850[SPARK-9850>https://issues.apache.org/jira/browse/SPARK-9850[SPARK-9850</a> Adaptive execution in Spark] for the design document. The work is currently in progress.</p> <p><a href=https://github.com/apache/spark/blob/master/core/src/main/scala/org/apache/spark/scheduler/DAGScheduler.scala#L661[DAGScheduler.submitMapStage>https://github.com/apache/spark/blob/master/core/src/main/scala/org/apache/spark/scheduler/DAGScheduler.scala#L661[DAGScheduler.submitMapStage</a>] method is used for adaptive query planning, to run map stages and look at statistics about their outputs before submitting downstream stages.</p> <p>== ScheduledExecutorService daemon services</p> <p>DAGScheduler uses the following ScheduledThreadPoolExecutors (with the policy of removing cancelled tasks from a work queue at time of cancellation):</p> <ul> <li><code>dag-scheduler-message</code> - a daemon thread pool using <code>j.u.c.ScheduledThreadPoolExecutor</code> with core pool size <code>1</code>. It is used to post a scheduler:DAGSchedulerEventProcessLoop.md#ResubmitFailedStages[ResubmitFailedStages] event when scheduler:DAGSchedulerEventProcessLoop.md#handleTaskCompletion-FetchFailed[<code>FetchFailed</code> is reported].</li> </ul> <p>They are created using <code>ThreadUtils.newDaemonSingleThreadScheduledExecutor</code> method that uses Guava DSL to instantiate a ThreadFactory.</p> <p>== [[getMissingParentStages]] Finding Missing Parent ShuffleMapStages For Stage</p> <h2 id=source-scala_15>[source, scala]<a class=headerlink href=#source-scala_15 title="Permanent link">&para;</a></h2> <p>getMissingParentStages( stage: Stage): List[Stage]</p> <hr> <p>getMissingParentStages finds missing parent scheduler:ShuffleMapStage.md[ShuffleMapStage]s in the dependency graph of the input <code>stage</code> (using the <a href=https://en.wikipedia.org/wiki/Breadth-first_search[breadth-first>https://en.wikipedia.org/wiki/Breadth-first_search[breadth-first</a> search algorithm]).</p> <p>Internally, getMissingParentStages starts with the <code>stage</code>'s RDD and walks up the tree of all parent RDDs to find &lt;<getcachelocs, uncached partitions>&gt;.</p> <p>NOTE: A <code>Stage</code> tracks the associated RDD using scheduler:Stage.md#rdd[<code>rdd</code> property].</p> <p>NOTE: An <em>uncached partition</em> of a RDD is a partition that has <code>Nil</code> in the &lt;<cachelocs, internal registry of partition locations per rdd>&gt; (which results in no RDD blocks in any of the active storage:BlockManager.md[BlockManager]s on executors).</p> <p>getMissingParentStages traverses the rdd/index.md#dependencies[parent dependencies of the RDD] and acts according to their type, i.e. <a href=../../rdd/ShuffleDependency/ >ShuffleDependency</a> or <a href=../../rdd/NarrowDependency/ >NarrowDependency</a>.</p> <p>NOTE: <a href=../../rdd/ShuffleDependency/ >ShuffleDependency</a> and <a href=../../rdd/NarrowDependency/ >NarrowDependency</a> are the main top-level <a href=../../rdd/Dependency/ >Dependencies</a>.</p> <p>For each <code>NarrowDependency</code>, <code>getMissingParentStages</code> simply marks the corresponding RDD to visit and moves on to a next dependency of a RDD or works on another unvisited parent RDD.</p> <p>NOTE: <a href=../../rdd/NarrowDependency/ >NarrowDependency</a> is a RDD dependency that allows for pipelined execution.</p> <p>getMissingParentStages focuses on <code>ShuffleDependency</code> dependencies.</p> <p>NOTE: <a href=../../rdd/ShuffleDependency/ >ShuffleDependency</a> is a RDD dependency that represents a dependency on the output of a <a href=../ShuffleMapStage/ >ShuffleMapStage</a>, i.e. <strong>shuffle map stage</strong>.</p> <p>For each <code>ShuffleDependency</code>, getMissingParentStages &lt;<getorcreateshufflemapstage, finds &lt;code>ShuffleMapStage</code> stages>&gt;. If the <code>ShuffleMapStage</code> is not <em>available</em>, it is added to the set of missing (map) stages.</p> <p>NOTE: A <code>ShuffleMapStage</code> is <em>available</em> when all its partitions are computed, i.e. results are available (as blocks).</p> <p>CAUTION: FIXME...IMAGE with ShuffleDependencies queried</p> <p>getMissingParentStages is used when DAGScheduler is requested to &lt;<submitstage, submit a stage>&gt; and handle &lt;<handlejobsubmitted, jobsubmitted>&gt; and &lt;<handlemapstagesubmitted, mapstagesubmitted>&gt; events.</p> <p>== [[submitMissingTasks]] Submitting Missing Tasks of Stage</p> <h2 id=source-scala_16>[source, scala]<a class=headerlink href=#source-scala_16 title="Permanent link">&para;</a></h2> <p>submitMissingTasks( stage: Stage, jobId: Int): Unit</p> <hr> <p>submitMissingTasks prints out the following DEBUG message to the logs:</p> <div class=highlight><pre><span></span><code>submitMissingTasks([stage])
</code></pre></div> <p>submitMissingTasks requests the given scheduler:Stage.md[Stage] for the scheduler:Stage.md#findMissingPartitions[missing partitions] (partitions that need to be computed).</p> <p>submitMissingTasks adds the stage to the &lt;<runningstages, runningstages>&gt; internal registry.</p> <p>submitMissingTasks notifies the &lt;<outputcommitcoordinator, outputcommitcoordinator>&gt; that scheduler:OutputCommitCoordinator.md#stageStart[stage execution started].</p> <p>[[submitMissingTasks-taskIdToLocations]] submitMissingTasks &lt;<getpreferredlocs, determines preferred locations>&gt; (<em>task locality preferences</em>) of the missing partitions.</p> <p>submitMissingTasks requests the stage for a scheduler:Stage.md#makeNewStageAttempt[new stage attempt].</p> <p>submitMissingTasks requests the &lt;<listenerbus, livelistenerbus>&gt; to scheduler:LiveListenerBus.md#post[post] a ROOT:SparkListener.md#SparkListenerStageSubmitted[SparkListenerStageSubmitted] event.</p> <p>submitMissingTasks uses the &lt;<closureserializer, closure serializer>&gt; to serializer:Serializer.md#serialize[serialize] the stage and create a so-called task binary. submitMissingTasks serializes the RDD (of the stage) and either the ShuffleDependency or the compute function based on the type of the stage, i.e. ShuffleMapStage and ResultStage, respectively.</p> <p>submitMissingTasks creates a ROOT:SparkContext.md#broadcast[broadcast variable] for the task binary.</p> <p>NOTE: That shows how important ROOT:Broadcast.md[]s are for Spark itself to distribute data among executors in a Spark application in the most efficient way.</p> <p>submitMissingTasks creates scheduler:Task.md[tasks] for every missing partition:</p> <ul> <li> <p>scheduler:ShuffleMapTask.md[ShuffleMapTasks] for a scheduler:ShuffleMapStage.md[ShuffleMapStage]</p> </li> <li> <p>scheduler:ResultTask.md[ResultTasks] for a scheduler:ResultStage.md[ResultStage]</p> </li> </ul> <p>If there are tasks to submit for execution (i.e. there are missing partitions in the stage), submitMissingTasks prints out the following INFO message to the logs:</p> <div class=highlight><pre><span></span><code>Submitting [size] missing tasks from [stage] ([rdd]) (first 15 tasks are for partitions [partitionIds])
</code></pre></div> <p>submitMissingTasks requests the &lt;<taskscheduler, taskscheduler>&gt; to scheduler:TaskScheduler.md#submitTasks[submit the tasks for execution] (as a new scheduler:TaskSet.md[TaskSet]).</p> <p>With no tasks to submit for execution, submitMissingTasks &lt;<markstageasfinished, marks the stage as finished successfully>&gt;.</p> <p>submitMissingTasks prints out the following DEBUG messages based on the type of the stage:</p> <div class=highlight><pre><span></span><code>Stage [stage] is actually done; (available: [isAvailable],available outputs: [numAvailableOutputs],partitions: [numPartitions])
</code></pre></div> <p>or</p> <div class=highlight><pre><span></span><code>Stage [stage] is actually done; (partitions: [numPartitions])
</code></pre></div> <p>for <code>ShuffleMapStage</code> and <code>ResultStage</code>, respectively.</p> <p>In the end, with no tasks to submit for execution, submitMissingTasks &lt;<submitwaitingchildstages, submits waiting child stages for execution>&gt; and exits.</p> <p>submitMissingTasks is used when DAGScheduler is requested to &lt;<submitstage, submit a stage for execution>&gt;.</p> <p>== [[getPreferredLocs]] Finding Preferred Locations for Missing Partitions</p> <h2 id=source-scala_17>[source, scala]<a class=headerlink href=#source-scala_17 title="Permanent link">&para;</a></h2> <p>getPreferredLocs( rdd/ RDD[_], partition: Int): Seq[TaskLocation]</p> <hr> <p>getPreferredLocs is simply an alias for the internal (recursive) &lt;<getpreferredlocsinternal, getpreferredlocsinternal>&gt;.</p> <p>getPreferredLocs is used when...FIXME</p> <p>== [[getCacheLocs]] Finding BlockManagers (Executors) for Cached RDD Partitions (aka Block Location Discovery)</p> <h2 id=source-scala_18>[source, scala]<a class=headerlink href=#source-scala_18 title="Permanent link">&para;</a></h2> <p>getCacheLocs( rdd/ RDD[_]): IndexedSeq[Seq[TaskLocation]]</p> <hr> <p>getCacheLocs gives scheduler:TaskLocation.md[TaskLocations] (block locations) for the partitions of the input <code>rdd</code>. getCacheLocs caches lookup results in &lt;<cachelocs, cachelocs>&gt; internal registry.</p> <p>NOTE: The size of the collection from getCacheLocs is exactly the number of partitions in <code>rdd</code> RDD.</p> <p>NOTE: The size of every scheduler:TaskLocation.md[TaskLocation] collection (i.e. every entry in the result of getCacheLocs) is exactly the number of blocks managed using storage:BlockManager.md[BlockManagers] on executors.</p> <p>Internally, getCacheLocs finds <code>rdd</code> in the &lt;<cachelocs, cachelocs>&gt; internal registry (of partition locations per RDD).</p> <p>If <code>rdd</code> is not in &lt;<cachelocs, cachelocs>&gt; internal registry, getCacheLocs branches per its storage:StorageLevel.md[storage level].</p> <p>For <code>NONE</code> storage level (i.e. no caching), the result is an empty locations (i.e. no location preference).</p> <p>For other non-<code>NONE</code> storage levels, getCacheLocs storage:BlockManagerMaster.md#getLocations-block-array[requests <code>BlockManagerMaster</code> for block locations] that are then mapped to scheduler:TaskLocation.md[TaskLocations] with the hostname of the owning <code>BlockManager</code> for a block (of a partition) and the executor id.</p> <p>NOTE: getCacheLocs uses &lt;<blockmanagermaster, blockmanagermaster>&gt; that was defined when &lt;<creating-instance, dagscheduler was created>&gt;.</p> <p>getCacheLocs records the computed block locations per partition (as scheduler:TaskLocation.md[TaskLocation]) in &lt;<cachelocs, cachelocs>&gt; internal registry.</p> <p>NOTE: getCacheLocs requests locations from <code>BlockManagerMaster</code> using storage:BlockId.md#RDDBlockId[RDDBlockId] with the RDD id and the partition indices (which implies that the order of the partitions matters to request proper blocks).</p> <p>NOTE: DAGScheduler uses scheduler:TaskLocation.md[TaskLocations] (with host and executor) while storage:BlockManagerMaster.md[BlockManagerMaster] uses storage:BlockManagerId.md[] (to track similar information, i.e. block locations).</p> <p>getCacheLocs is used when DAGScheduler is requested to finds &lt;<getmissingparentstages, missing parent mapstages>&gt; and &lt;<getpreferredlocsinternal, getpreferredlocsinternal>&gt;.</p> <p>== [[getPreferredLocsInternal]] Finding Placement Preferences for RDD Partition (recursively)</p> <h2 id=source-scala_19>[source, scala]<a class=headerlink href=#source-scala_19 title="Permanent link">&para;</a></h2> <p>getPreferredLocsInternal( rdd/ RDD[<em>], partition: Int, visited: HashSet[(RDD[</em>], Int)]): Seq[TaskLocation]</p> <hr> <p>getPreferredLocsInternal first &lt;<getcachelocs, finds the &lt;code>TaskLocations</code> for the <code>partition</code> of the <code>rdd</code>>&gt; (using &lt;<cachelocs, cachelocs>&gt; internal cache) and returns them.</p> <p>Otherwise, if not found, getPreferredLocsInternal rdd/index.md#preferredLocations[requests <code>rdd</code> for the preferred locations of <code>partition</code>] and returns them.</p> <p>NOTE: Preferred locations of the partitions of a RDD are also called <em>placement preferences</em> or <em>locality preferences</em>.</p> <p>Otherwise, if not found, getPreferredLocsInternal finds the first parent <a href=../../rdd/NarrowDependency/ >NarrowDependency</a> and (recursively) &lt;<getpreferredlocsinternal, finds &lt;code>TaskLocations</code>>&gt;.</p> <p>If all the attempts fail to yield any non-empty result, getPreferredLocsInternal returns an empty collection of scheduler:TaskLocation.md[TaskLocations].</p> <p>getPreferredLocsInternal is used when DAGScheduler is requested for the &lt;<getpreferredlocs, preferred locations for missing partitions>&gt;.</p> <p>== [[stop]] Stopping DAGScheduler</p> <h2 id=source-scala_20>[source, scala]<a class=headerlink href=#source-scala_20 title="Permanent link">&para;</a></h2> <h2 id=stop-unit>stop(): Unit<a class=headerlink href=#stop-unit title="Permanent link">&para;</a></h2> <p>stop stops the internal <code>dag-scheduler-message</code> thread pool, &lt;<event-loop, dag-scheduler-event-loop>&gt;, and scheduler:TaskScheduler.md#stop[TaskScheduler].</p> <p>stop is used when...FIXME</p> <p>== [[updateAccumulators]] Updating Accumulators with Partial Values from Completed Tasks</p> <h2 id=source-scala_21>[source, scala]<a class=headerlink href=#source-scala_21 title="Permanent link">&para;</a></h2> <p>updateAccumulators( event: CompletionEvent): Unit</p> <hr> <p>updateAccumulators merges the partial values of accumulators from a completed task into their "source" accumulators on the driver.</p> <p>NOTE: It is called by &lt;<handletaskcompletion, handletaskcompletion>&gt;.</p> <p>For each ROOT:spark-accumulators.md#AccumulableInfo[AccumulableInfo] in the <code>CompletionEvent</code>, a partial value from a task is obtained (from <code>AccumulableInfo.update</code>) and added to the driver's accumulator (using <code>Accumulable.++=</code> method).</p> <p>For named accumulators with the update value being a non-zero value, i.e. not <code>Accumulable.zero</code>:</p> <ul> <li><code>stage.latestInfo.accumulables</code> for the <code>AccumulableInfo.id</code> is set</li> <li><code>CompletionEvent.taskInfo.accumulables</code> has a new ROOT:spark-accumulators.md#AccumulableInfo[AccumulableInfo] added.</li> </ul> <p>CAUTION: FIXME Where are <code>Stage.latestInfo.accumulables</code> and <code>CompletionEvent.taskInfo.accumulables</code> used?</p> <p>updateAccumulators is used when DAGScheduler is requested to &lt;<handletaskcompletion, handle a task completion>&gt;.</p> <p>== [[checkBarrierStageWithNumSlots]] checkBarrierStageWithNumSlots Method</p> <h2 id=source-scala_22>[source, scala]<a class=headerlink href=#source-scala_22 title="Permanent link">&para;</a></h2> <p>checkBarrierStageWithNumSlots( rdd/ RDD[_]): Unit</p> <hr> <p>checkBarrierStageWithNumSlots...FIXME</p> <p>checkBarrierStageWithNumSlots is used when DAGScheduler is requested to create &lt;<createshufflemapstage, shufflemapstage>&gt; and &lt;<createresultstage, resultstage>&gt; stages.</p> <p>== [[killTaskAttempt]] Killing Task</p> <h2 id=source-scala_23>[source, scala]<a class=headerlink href=#source-scala_23 title="Permanent link">&para;</a></h2> <p>killTaskAttempt( taskId: Long, interruptThread: Boolean, reason: String): Boolean</p> <hr> <p>killTaskAttempt requests the &lt;<taskscheduler, taskscheduler>&gt; to scheduler:TaskScheduler.md#killTaskAttempt[kill a task].</p> <p>killTaskAttempt is used when SparkContext is requested to ROOT:SparkContext.md#killTaskAttempt[kill a task].</p> <p>== [[cleanUpAfterSchedulerStop]] cleanUpAfterSchedulerStop Method</p> <h2 id=source-scala_24>[source, scala]<a class=headerlink href=#source-scala_24 title="Permanent link">&para;</a></h2> <h2 id=cleanupafterschedulerstop-unit>cleanUpAfterSchedulerStop(): Unit<a class=headerlink href=#cleanupafterschedulerstop-unit title="Permanent link">&para;</a></h2> <p>cleanUpAfterSchedulerStop...FIXME</p> <p>cleanUpAfterSchedulerStop is used when DAGSchedulerEventProcessLoop is requested to scheduler:DAGSchedulerEventProcessLoop.md#onStop[onStop].</p> <p>== [[removeExecutorAndUnregisterOutputs]] removeExecutorAndUnregisterOutputs Method</p> <h2 id=source-scala_25>[source, scala]<a class=headerlink href=#source-scala_25 title="Permanent link">&para;</a></h2> <p>removeExecutorAndUnregisterOutputs( execId: String, fileLost: Boolean, hostToUnregisterOutputs: Option[String], maybeEpoch: Option[Long] = None): Unit</p> <hr> <p>removeExecutorAndUnregisterOutputs...FIXME</p> <p>removeExecutorAndUnregisterOutputs is used when DAGScheduler is requested to handle &lt;<handletaskcompletion, task completion>&gt; (due to a fetch failure) and &lt;<handleexecutorlost, executor lost>&gt; events.</p> <p>== [[markMapStageJobsAsFinished]] markMapStageJobsAsFinished Method</p> <h2 id=source-scala_26>[source, scala]<a class=headerlink href=#source-scala_26 title="Permanent link">&para;</a></h2> <p>markMapStageJobsAsFinished( shuffleStage: ShuffleMapStage): Unit</p> <hr> <p>markMapStageJobsAsFinished...FIXME</p> <p>markMapStageJobsAsFinished is used when DAGScheduler is requested to &lt;<submitmissingtasks, submit missing tasks>&gt; (of a ShuffleMapStage that has just been computed) and &lt;<handletaskcompletion, handle a task completion>&gt; (of a ShuffleMapStage).</p> <p>== [[updateJobIdStageIdMaps]] updateJobIdStageIdMaps Method</p> <h2 id=source-scala_27>[source, scala]<a class=headerlink href=#source-scala_27 title="Permanent link">&para;</a></h2> <p>updateJobIdStageIdMaps( jobId: Int, stage: Stage): Unit</p> <hr> <p>updateJobIdStageIdMaps...FIXME</p> <p>updateJobIdStageIdMaps is used when DAGScheduler is requested to create &lt;<createshufflemapstage, shufflemapstage>&gt; and &lt;<createresultstage, resultstage>&gt; stages.</p> <p>== [[executorHeartbeatReceived]] executorHeartbeatReceived Method</p> <h2 id=source-scala_28>[source, scala]<a class=headerlink href=#source-scala_28 title="Permanent link">&para;</a></h2> <p>executorHeartbeatReceived( execId: String, // (taskId, stageId, stageAttemptId, accumUpdates) accumUpdates: Array[(Long, Int, Int, Seq[AccumulableInfo])], blockManagerId: BlockManagerId): Boolean</p> <hr> <p>executorHeartbeatReceived posts a ROOT:SparkListener.md#SparkListenerExecutorMetricsUpdate[SparkListenerExecutorMetricsUpdate] (to &lt;<listenerbus, listenerbus>&gt;) and informs storage:BlockManagerMaster.md[BlockManagerMaster] that <code>blockManagerId</code> block manager is alive (by posting storage:BlockManagerMaster.md#BlockManagerHeartbeat[BlockManagerHeartbeat]).</p> <p>executorHeartbeatReceived is used when TaskSchedulerImpl is requested to scheduler:TaskSchedulerImpl.md#executorHeartbeatReceived[handle an executor heartbeat].</p> <p>== [[postTaskEnd]] postTaskEnd Method</p> <h2 id=source-scala_29>[source, scala]<a class=headerlink href=#source-scala_29 title="Permanent link">&para;</a></h2> <p>postTaskEnd( event: CompletionEvent): Unit</p> <hr> <p>postTaskEnd...FIXME</p> <p>postTaskEnd is used when DAGScheduler is requested to &lt;<handletaskcompletion, handle a task completion>&gt;.</p> <p>== Event Handlers</p> <p>=== [[doCancelAllJobs]] AllJobsCancelled Event Handler</p> <h2 id=source-scala_30>[source, scala]<a class=headerlink href=#source-scala_30 title="Permanent link">&para;</a></h2> <h2 id=docancelalljobs-unit>doCancelAllJobs(): Unit<a class=headerlink href=#docancelalljobs-unit title="Permanent link">&para;</a></h2> <p>doCancelAllJobs...FIXME</p> <p>doCancelAllJobs is used when DAGSchedulerEventProcessLoop is requested to handle an scheduler:DAGSchedulerEventProcessLoop.md#AllJobsCancelled[AllJobsCancelled] event and scheduler:DAGSchedulerEventProcessLoop.md#onError[onError].</p> <p>=== [[handleBeginEvent]] BeginEvent Event Handler</p> <h2 id=source-scala_31>[source, scala]<a class=headerlink href=#source-scala_31 title="Permanent link">&para;</a></h2> <p>handleBeginEvent( task: Task[_], taskInfo: TaskInfo): Unit</p> <hr> <p>handleBeginEvent...FIXME</p> <p>handleBeginEvent is used when DAGSchedulerEventProcessLoop is requested to handle a scheduler:DAGSchedulerEvent.md#BeginEvent[BeginEvent] event.</p> <p>=== [[handleTaskCompletion]] CompletionEvent Event Handler</p> <h2 id=source-scala_32>[source, scala]<a class=headerlink href=#source-scala_32 title="Permanent link">&para;</a></h2> <p>handleTaskCompletion( event: CompletionEvent): Unit</p> <hr> <p>handleTaskCompletion...FIXME</p> <p>handleTaskCompletion is used when DAGSchedulerEventProcessLoop is requested to handle a scheduler:DAGSchedulerEvent.md#CompletionEvent[CompletionEvent] event.</p> <p>=== [[handleExecutorAdded]] ExecutorAdded Event Handler</p> <h2 id=source-scala_33>[source, scala]<a class=headerlink href=#source-scala_33 title="Permanent link">&para;</a></h2> <p>handleExecutorAdded( execId: String, host: String): Unit</p> <hr> <p>handleExecutorAdded...FIXME</p> <p>handleExecutorAdded is used when DAGSchedulerEventProcessLoop is requested to handle an scheduler:DAGSchedulerEvent.md#ExecutorAdded[ExecutorAdded] event.</p> <p>=== [[handleExecutorLost]] ExecutorLost Event Handler</p> <h2 id=source-scala_34>[source, scala]<a class=headerlink href=#source-scala_34 title="Permanent link">&para;</a></h2> <p>handleExecutorLost( execId: String, workerLost: Boolean): Unit</p> <hr> <p>handleExecutorLost...FIXME</p> <p>handleExecutorLost is used when DAGSchedulerEventProcessLoop is requested to handle an scheduler:DAGSchedulerEvent.md#ExecutorLost[ExecutorLost] event.</p> <p>=== [[handleGetTaskResult]] GettingResultEvent Event Handler</p> <h2 id=source-scala_35>[source, scala]<a class=headerlink href=#source-scala_35 title="Permanent link">&para;</a></h2> <p>handleGetTaskResult( taskInfo: TaskInfo): Unit</p> <hr> <p>handleGetTaskResult...FIXME</p> <p>handleGetTaskResult is used when DAGSchedulerEventProcessLoop is requested to handle a scheduler:DAGSchedulerEvent.md#GettingResultEvent[GettingResultEvent] event.</p> <p>=== [[handleJobCancellation]] JobCancelled Event Handler</p> <h2 id=source-scala_36>[source, scala]<a class=headerlink href=#source-scala_36 title="Permanent link">&para;</a></h2> <p>handleJobCancellation( jobId: Int, reason: Option[String]): Unit</p> <hr> <p>handleJobCancellation...FIXME</p> <p>handleJobCancellation is used when DAGScheduler is requested to handle a scheduler:DAGSchedulerEvent.md#JobCancelled[JobCancelled] event, &lt;<docancelalljobs, docancelalljobs>&gt;, &lt;<handlejobgroupcancelled, handlejobgroupcancelled>&gt;, &lt;<handlestagecancellation, handlestagecancellation>&gt;.</p> <p>=== [[handleJobGroupCancelled]] JobGroupCancelled Event Handler</p> <h2 id=source-scala_37>[source, scala]<a class=headerlink href=#source-scala_37 title="Permanent link">&para;</a></h2> <p>handleJobGroupCancelled( groupId: String): Unit</p> <hr> <p>handleJobGroupCancelled...FIXME</p> <p>handleJobGroupCancelled is used when DAGScheduler is requested to handle scheduler:DAGSchedulerEvent.md#JobGroupCancelled[JobGroupCancelled] event.</p> <p>=== [[handleJobSubmitted]] JobSubmitted Event Handler</p> <h2 id=source-scala_38>[source, scala]<a class=headerlink href=#source-scala_38 title="Permanent link">&para;</a></h2> <p>handleJobSubmitted( jobId: Int, finalrdd/ RDD[<em>], func: (TaskContext, Iterator[</em>]) =&gt; _, partitions: Array[Int], callSite: CallSite, listener: JobListener, properties: Properties): Unit</p> <hr> <p>handleJobSubmitted scheduler:DAGScheduler.md#createResultStage[creates a new <code>ResultStage</code>] (as <code>finalStage</code> in the picture below) given the input <code>finalRDD</code>, <code>func</code>, <code>partitions</code>, <code>jobId</code> and <code>callSite</code>.</p> <p>.<code>DAGScheduler.handleJobSubmitted</code> Method image::dagscheduler-handleJobSubmitted.png[align="center"]</p> <p>handleJobSubmitted creates an scheduler:spark-scheduler-ActiveJob.md[ActiveJob] (with the input <code>jobId</code>, <code>callSite</code>, <code>listener</code>, <code>properties</code>, and the scheduler:ResultStage.md[ResultStage]).</p> <p>handleJobSubmitted scheduler:DAGScheduler.md#clearCacheLocs[clears the internal cache of RDD partition locations].</p> <p>CAUTION: FIXME Why is this clearing here so important?</p> <p>You should see the following INFO messages in the logs:</p> <div class=highlight><pre><span></span><code>Got job [id] ([callSite]) with [number] output partitions
Final stage: [stage] ([name])
Parents of final stage: [parents]
Missing parents: [missingStages]
</code></pre></div> <p>handleJobSubmitted then registers the new job in scheduler:DAGScheduler.md#jobIdToActiveJob[jobIdToActiveJob] and scheduler:DAGScheduler.md#activeJobs[activeJobs] internal registries, and scheduler:ResultStage.md#setActiveJob[with the final <code>ResultStage</code>].</p> <p>NOTE: <code>ResultStage</code> can only have one <code>ActiveJob</code> registered.</p> <p>handleJobSubmitted scheduler:DAGScheduler.md#jobIdToStageIds[finds all the registered stages for the input <code>jobId</code>] and collects scheduler:Stage.md#latestInfo[their latest <code>StageInfo</code>].</p> <p>In the end, handleJobSubmitted posts ROOT:SparkListener.md#SparkListenerJobStart[SparkListenerJobStart] message to scheduler:LiveListenerBus.md[] and scheduler:DAGScheduler.md#submitStage[submits the stage].</p> <p>handleJobSubmitted is used when DAGSchedulerEventProcessLoop is requested to handle a scheduler:DAGSchedulerEvent.md#JobSubmitted[JobSubmitted] event.</p> <p>=== [[handleMapStageSubmitted]] MapStageSubmitted Event Handler</p> <h2 id=source-scala_39>[source, scala]<a class=headerlink href=#source-scala_39 title="Permanent link">&para;</a></h2> <p>handleMapStageSubmitted( jobId: Int, dependency: ShuffleDependency[_, _, _], callSite: CallSite, listener: JobListener, properties: Properties): Unit</p> <hr> <p>handleMapStageSubmitted...FIXME</p> <p>handleMapStageSubmitted is used when DAGSchedulerEventProcessLoop is requested to handle a scheduler:DAGSchedulerEvent.md#MapStageSubmitted[MapStageSubmitted] event.</p> <p>=== [[resubmitFailedStages]] ResubmitFailedStages Event Handler</p> <h2 id=source-scala_40>[source, scala]<a class=headerlink href=#source-scala_40 title="Permanent link">&para;</a></h2> <h2 id=resubmitfailedstages-unit>resubmitFailedStages(): Unit<a class=headerlink href=#resubmitfailedstages-unit title="Permanent link">&para;</a></h2> <p>resubmitFailedStages...FIXME</p> <p>resubmitFailedStages is used when DAGSchedulerEventProcessLoop is requested to handle a scheduler:DAGSchedulerEvent.md#ResubmitFailedStages[ResubmitFailedStages] event.</p> <p>=== [[handleSpeculativeTaskSubmitted]] SpeculativeTaskSubmitted Event Handler</p> <h2 id=source-scala_41>[source, scala]<a class=headerlink href=#source-scala_41 title="Permanent link">&para;</a></h2> <h2 id=handlespeculativetasksubmitted-unit>handleSpeculativeTaskSubmitted(): Unit<a class=headerlink href=#handlespeculativetasksubmitted-unit title="Permanent link">&para;</a></h2> <p>handleSpeculativeTaskSubmitted...FIXME</p> <p>handleSpeculativeTaskSubmitted is used when DAGSchedulerEventProcessLoop is requested to handle a scheduler:DAGSchedulerEvent.md#SpeculativeTaskSubmitted[SpeculativeTaskSubmitted] event.</p> <p>=== [[handleStageCancellation]] StageCancelled Event Handler</p> <h2 id=source-scala_42>[source, scala]<a class=headerlink href=#source-scala_42 title="Permanent link">&para;</a></h2> <h2 id=handlestagecancellation-unit>handleStageCancellation(): Unit<a class=headerlink href=#handlestagecancellation-unit title="Permanent link">&para;</a></h2> <p>handleStageCancellation...FIXME</p> <p>handleStageCancellation is used when DAGSchedulerEventProcessLoop is requested to handle a scheduler:DAGSchedulerEvent.md#StageCancelled[StageCancelled] event.</p> <p>=== [[handleTaskSetFailed]] TaskSetFailed Event Handler</p> <h2 id=source-scala_43>[source, scala]<a class=headerlink href=#source-scala_43 title="Permanent link">&para;</a></h2> <h2 id=handletasksetfailed-unit>handleTaskSetFailed(): Unit<a class=headerlink href=#handletasksetfailed-unit title="Permanent link">&para;</a></h2> <p>handleTaskSetFailed...FIXME</p> <p>handleTaskSetFailed is used when DAGSchedulerEventProcessLoop is requested to handle a scheduler:DAGSchedulerEvent.md#TaskSetFailed[TaskSetFailed] event.</p> <p>=== [[handleWorkerRemoved]] WorkerRemoved Event Handler</p> <h2 id=source-scala_44>[source, scala]<a class=headerlink href=#source-scala_44 title="Permanent link">&para;</a></h2> <p>handleWorkerRemoved( workerId: String, host: String, message: String): Unit</p> <hr> <p>handleWorkerRemoved...FIXME</p> <p>handleWorkerRemoved is used when DAGSchedulerEventProcessLoop is requested to handle a scheduler:DAGSchedulerEvent.md#WorkerRemoved[WorkerRemoved] event.</p> <p>== [[logging]] Logging</p> <p>Enable <code>ALL</code> logging level for <code>org.apache.spark.scheduler.DAGScheduler</code> logger to see what happens inside.</p> <p>Add the following line to <code>conf/log4j.properties</code>:</p> <h2 id=source>[source]<a class=headerlink href=#source title="Permanent link">&para;</a></h2> <h2 id=log4jloggerorgapachesparkschedulerdagschedulerall>log4j.logger.org.apache.spark.scheduler.DAGScheduler=ALL<a class=headerlink href=#log4jloggerorgapachesparkschedulerdagschedulerall title="Permanent link">&para;</a></h2> <p>Refer to ROOT:spark-logging.md[Logging].</p> <p>== [[internal-properties]] Internal Properties</p> <p>[cols="30m,70",options="header",width="100%"] |=== | Name | Description</p> <p>| failedEpoch | [[failedEpoch]] The lookup table of lost executors and the epoch of the event.</p> <p>| failedStages | [[failedStages]] Stages that failed due to fetch failures (when a scheduler:DAGSchedulerEventProcessLoop.md#handleTaskCompletion-FetchFailed[task fails with <code>FetchFailed</code> exception]).</p> <p>| jobIdToActiveJob | [[jobIdToActiveJob]] The lookup table of <code>ActiveJob</code>s per job id.</p> <p>| jobIdToStageIds | [[jobIdToStageIds]] The lookup table of all stages per <code>ActiveJob</code> id</p> <p>| metricsSource | [[metricsSource]] metrics:spark-scheduler-DAGSchedulerSource.md[DAGSchedulerSource]</p> <p>| nextJobId | [[nextJobId]] The next job id counting from <code>0</code>.</p> <p>Used when DAGScheduler &lt;<submitjob, submits a job>&gt; and &lt;<submitmapstage, a map stage>&gt;, and &lt;<runapproximatejob, runs an approximate job>&gt;.</p> <p>| nextStageId | [[nextStageId]] The next stage id counting from <code>0</code>.</p> <p>Used when DAGScheduler creates a &lt;<createshufflemapstage, shuffle map stage>&gt; and a &lt;<createresultstage, result stage>&gt;. It is the key in &lt;<stageidtostage, stageidtostage>&gt;.</p> <p>| runningStages | [[runningStages]] The set of stages that are currently "running".</p> <p>A stage is added when &lt;<submitmissingtasks, submitmissingtasks>&gt; gets executed (without first checking if the stage has not already been added).</p> <p>| shuffleIdToMapStage | [[shuffleIdToMapStage]] The lookup table of scheduler:ShuffleMapStage.md[ShuffleMapStage]s per <a href=../../rdd/ShuffleDependency/ >ShuffleDependency</a>.</p> <p>| stageIdToStage | [[stageIdToStage]] The lookup table for stages per their ids.</p> <p>Used when DAGScheduler &lt;<createshufflemapstage, creates a shuffle map stage>&gt;, &lt;<createresultstage, creates a result stage>&gt;, &lt;<cleanupstateforjobandindependentstages, cleans up job state and independent stages>&gt;, is informed that scheduler:DAGSchedulerEventProcessLoop.md#handleBeginEvent[a task is started], scheduler:DAGSchedulerEventProcessLoop.md#handleTaskSetFailed[a taskset has failed], scheduler:DAGSchedulerEventProcessLoop.md#handleJobSubmitted[a job is submitted (to compute a <code>ResultStage</code>)], scheduler:DAGSchedulerEventProcessLoop.md#handleMapStageSubmitted[a map stage was submitted], scheduler:DAGSchedulerEventProcessLoop.md#handleTaskCompletion[a task has completed] or scheduler:DAGSchedulerEventProcessLoop.md#handleStageCancellation[a stage was cancelled], &lt;<updateaccumulators, updates accumulators>&gt;, &lt;<abortstage, aborts a stage>&gt; and &lt;<failjobandindependentstages, fails a job and independent stages>&gt;.</p> <p>| waitingStages | [[waitingStages]] The stages with parents to be computed</p> <p>|===</p> <hr> <div class=md-source-date> <small> Last update: 2020-10-09 </small> </div> </article> </div> </div> </main> <footer class=md-footer> <div class=md-footer-nav> <nav class="md-footer-nav__inner md-grid" aria-label=Footer> <a href=../ class="md-footer-nav__link md-footer-nav__link--prev" rel=prev> <div class="md-footer-nav__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg> </div> <div class=md-footer-nav__title> <div class=md-ellipsis> <span class=md-footer-nav__direction> Previous </span> Spark Scheduler </div> </div> </a> <a href=../DAGSchedulerEvent/ class="md-footer-nav__link md-footer-nav__link--next" rel=next> <div class=md-footer-nav__title> <div class=md-ellipsis> <span class=md-footer-nav__direction> Next </span> DAGSchedulerEvent </div> </div> <div class="md-footer-nav__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11H4z"/></svg> </div> </a> </nav> </div> <div class="md-footer-meta md-typeset"> <div class="md-footer-meta__inner md-grid"> <div class=md-footer-copyright> <div class=md-footer-copyright__highlight> Copyright &copy; 2020 <a href=https://twitter.com/jaceklaskowski target=_blank rel=noopener>Jacek Laskowski</a> </div> Made with <a href=https://squidfunk.github.io/mkdocs-material/ target=_blank rel=noopener> Material for MkDocs </a> </div> <div class=md-footer-social> <a href=https://github.com/jaceklaskowski target=_blank rel=noopener title=github.com class=md-footer-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 496 512"><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg> </a> <a href=https://twitter.com/jaceklaskowski target=_blank rel=noopener title=twitter.com class=md-footer-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 512 512"><path d="M459.37 151.716c.325 4.548.325 9.097.325 13.645 0 138.72-105.583 298.558-298.558 298.558-59.452 0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055 0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421 0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391 0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04 0-57.828 46.782-104.934 104.934-104.934 30.213 0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253z"/></svg> </a> <a href=https://linkedin.com/in/jaceklaskowski target=_blank rel=noopener title=linkedin.com class=md-footer-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><path d="M416 32H31.9C14.3 32 0 46.5 0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6 0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3zM135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3 0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2 0 38.5 17.3 38.5 38.5 0 21.3-17.2 38.5-38.5 38.5zm282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6 0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2 0 79.7 44.3 79.7 101.9V416z"/></svg> </a> </div> </div> </div> </footer> </div> <script src=../../assets/javascripts/vendor.77e55a48.min.js></script> <script src=../../assets/javascripts/bundle.9554a270.min.js></script><script id=__lang type=application/json>{"clipboard.copy": "Copy to clipboard", "clipboard.copied": "Copied to clipboard", "search.config.lang": "en", "search.config.pipeline": "trimmer, stopWordFilter", "search.config.separator": "[\\s\\-]+", "search.result.placeholder": "Type to start searching", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.term.missing": "Missing"}</script> <script>
        app = initialize({
          base: "../..",
          features: ['navigation.tabs', 'navigation.instant'],
          search: Object.assign({
            worker: "../../assets/javascripts/worker/search.4ac00218.min.js"
          }, typeof search !== "undefined" && search)
        })
      </script> </body> </html>